year,title,abstract,full_text
1987,Bit-Serial Neural Networks,,573 BIT - SERIAL NEURAL  NETWORKS Alan F.  Murray
1987,Connectivity Versus Entropy,,1 CONNECTIVITY VERSUS ENTROPY Yaser  S.  Abu-Mostafa California  Institute  of Technology Pasadena
1987,The Hopfield Model with Multi-Level Neurons,,278 THE HOPFIELD MODEL WITH MUL TI-LEVEL NEURONS Michael Fleisher Department of Electrical Engineering Technion - Israel Institute of Technology Haifa 32000
1987,How Neural Nets Work,,442 Alan  Lapedes Robert  Farber Theoretical Division How  Neural  Nets  Work Los  Alamos  National Laboratory Los  Alamos
1987,Spatial Organization of Neural Networks: A Probabilistic Modeling Approach,,740 SPATIAL  ORGANIZATION  OF  NEURAL  NEn~ORKS: A PROBABILISTIC  MODELING  APPROACH A.  Stafylopatis M.  Dikaiakos D.  Kontoravdis National  Technical  University  of  Athens
1987,A Neural-Network Solution to the Concentrator Assignment Problem,,775 A  NEURAL-NETWORK  SOLUTION TO  THE  CONCENTRATOR ASSIGNNlENT  PROBLEM Gene  A.  Tagliarini Edward  W.  Page Department of Computer  Science
1987,LEARNING BY STATE RECURRENCE DETECTION,,642 LEARNING BY ST ATE RECURRENCE DETECfION Bruce E. Rosen
1987,Stability Results for Neural Networks,,554 STABILITY RESULTS  FOR NEURAL  NETWORKS A.  N.  Michell
1987,Introduction to a System for Implementing Neural Net Connections on SIMD Architectures,,804 INTRODUCTION TO A  SYSTEM FOR IMPLEMENTING NEURAL  NET CONNECTIONS ON SIMD  ARCHITECTURES Sherryl Tomboulian Institute for  Computer Applications  in Science and Engineering NASA  Langley Research Center
1987,Optimization with Artificial Neural Network Systems: A Mapping Principle and a Comparison to Gradient Based Methods,,474 OPTIMIZA nON WITH ARTIFICIAL NEURAL NETWORK SYSTEMS: A MAPPING  PRINCIPLE AND A COMPARISON TO GRADIENT BASED METHODS t Harrison MonFook Leong Research Institute  for Advanced Computer Science NASA Ames Research  Center 230-5 Moett  Field
1987,Optimal Neural Spike Classification,,95 OPTIMAL NEURAL SPIKE  CLASSIFICATION Amir  F.  Atiya(*)  and  James  M.  Bower(**) (*)  Dept.  of  Electrical Engineering (**)  Division  of  Biology California Institute of Technology Ca 91125 Abstract Being able  to record the electrical activities of a  number of neurons simultaneously is  likely to be important in  the study of the functional organization of networks of real neurons.  Using one  extracellular  microelectrode  to  record  from  several neurons  is  one  approach  to  studying the  response  properties  of sets  of  adjacent  and  therefore  likely  related  neurons.  However
1987,REFLEXIVE ASSOCIATIVE MEMORIES,,495 REFLEXIVE ASSOCIATIVE MEMORIES Laguna Research Laboratory
1987,The Performance of Convex Set Projection Based Neural Networks,,534 The  Performance  of  Convex  Set  projection  Based  Neural  Networks Robert  J.  Marks  II
1987,Speech Recognition Experiments with Perceptrons,,144 SPEECH RECOGNITION EXPERIMENTS WITH PERCEPTRONS D.  J. Burr Bell  Communications Research Morristown
1987,On Properties of Networks of Neuron-Like Elements,,41 ON  PROPERTIES OF NETWORKS OF  NEURON-LIKE ELEMENTS Pierre Baldi· and Santosh S.  Venkatesht 15  December 1987 Abstract The  complexity  and  computational  capacity  of multi-layered
1987,Ensemble' Boltzmann Units have Collective Computational Properties like those of Hopfield and Tank Neurons,,223 'Ensemble'  Boltzmann Units have  Collective Computational Properties like  those of Hopfield  and  Tank Neurons Mark Derthick and  Joe Tebelskis Department of Computer Science Carnegie-Mellon University 1  Introduction There  are  three  existing  connection::
1987,On Tropistic Processing and Its Applications,,262 ON  TROPISTIC  PROCESSING  AND  ITS  APPLICATIONS Manuel  F.  Fernandez General  Electric  Advanced  Technology  Laboratories Syracuse
1987,Neuromorphic Networks Based on Sparse Optical Orthogonal Codes,,814 NEUROMORPHIC  NETWORKS  BASED ON  SPARSE  OPTICAL  ORTHOGONAL  CODES Mario P. Vecchi and Jawad A.  Salehi Bell Communications Research 435  South Street Morristown
1987,A 'Neural' Network that Learns to Play Backgammon,,794 A 'Neural' Network that Learns to Play Backgammon G. Tesauro Center for Complex Systems Research
1987,Learning Representations by Recirculation,,358 LEARNING REPRESENTATIONS BY RECIRCULATION Computer Science and Psychology Departments
1987,A Computer Simulation of Cerebral Neocortex: Computational Capabilities of Nonlinear Neural Networks,,A  COMPUTER  SIMULATION  OF  CEREBRAL  NEOCORTEX: COMPUTATIONAL  CAPABILITIES  OF  NONLINEAR  NEURAL  NETWORKS 715 Alexander  Singer*  and  John  P.  Donoghue** *Department  of  Biophysics
1987,PATTERN CLASS DEGENERACY IN AN UNRESTRICTED STORAGE DENSITY MEMORY,,674 P A 'ITERN CLASS DEGENERACY IN AN UNRESTRICfED STORAGE DENSITY MEMORY Christopher L. Scofield
1987,Strategies for Teaching Layered Networks Classification Tasks,,850 Strategies for  Teaching  Layered  Networks Classification Tasks Ben  S.  Wittner 1  and John S.  Denker AT&T  Bell  Laboratories Holmdel
1987,Invariant Object Recognition Using a Distributed Associative Memory,,830 Invariant Object Recognition Using a  Distributed Associative Memory Harry Wechsler and George Lee Zimmerman Department or Electrical Engineering University or Minnesota Minneapolis
1987,Cycles: A Simulation Tool for Studying Cyclic Neural Networks,,290 CYCLES:  A  Simulation Tool for  Studying Cyclic Neural  Networks Texas Instruments Incorporated
1987,Learning on a General Network,,22 LEARNING  ON A  GENERAL NETWORK Amir F.  Atiya Department of Electrical Engineering California Institute of Technology Ca 91125 Abstract This paper generalizes the backpropagation method to a  general network containing feed(cid:173)back t
1987,Neural Net and Traditional Classifiers,,387 Neural Net  and  Traditional Classifiers1 William  Y.  Huang  and  Richard P.  Lippmann MIT Lincoln  Laboratory Lexington
1987,Scaling Properties of Coarse-Coded Symbol Memories,,652 Scaling Properties of Coarse-Coded  Symbol Memories Ronald  Rosenfeld David S.  Touretzky Computer Science Department Carnegie Mellon  University Pittsburgh
1987,Synchronization in Neural Nets,,824 SYNCHRONIZATION IN  NEURAL NETS University of California Los Angeles
1987,A NEURAL NETWORK CLASSIFIER BASED ON CODING THEORY,,174 A Neural Network Classifier Based on Coding Theory Tzt-Dar Chlueh and Rodney Goodman eanrornla Instltute of Technology. Pasadena. eanromla 91125 ABSTRACT The new neural network classifier we propose transforms the classification problem into the coding theory problem of decoding a noisy codeword. An input vector in the feature space is transformed into an internal representation which is a codeword in the code space
1987,Microelectronic Implementations of Connectionist Neural Networks,,515 MICROELECTRONIC  IMPLEMENTATIONS  OF  CONNECTIONIST NEURAL  NETWORKS Stuart Mackie
1987,Analysis of Distributed Representation of Constituent Structure in Connectionist Systems,,730 Analysis of distributed representation of constituent structure in connectionist systems Department of Computer Science
1987,Hierarchical Learning Control - An Approach with Neuron-Like Associative Memories,,249 HIERARCHICAL  LEARNING  CONTROL  -AN  APPROACH  WITH  NEURON-LIKE  ASSOCIATIVE  MEMORIES ISRA  Systemtechnik  GmbH
1987,Presynaptic Neural Information Processing,,154 PRESYNApnC NEURAL INFORMAnON PROCESSING L.  R.  Carley Department of Electrical and  Computer  Engineering Carnegie  Mellon  University
1987,An Optimization Network for Matrix Inversion,,397 AN  OPTIMIZATION  NETWORK  FOR  MATRIX  INVERSION Ju-Seog  Jang
1987,Basins of Attraction for Electronic Neural Networks,,524 BASINS  OF  ATTRACTION  FOR ELECTRONIC  NEURAL  NETWORKS C.  M.  Marcus R.  M.  Westervelt Division  of  Applied  Sciences  and  Department  of  Physics Harvard  University
1987,Programmable Synaptic Chip for Electronic Neural Networks,,564 PROGRAMMABLE  SYNAPTIC  CHIP  FOR ELECTRONIC  NEURAL  NETWORKS A.  Moopenn
1987,Learning a Color Algorithm from Examples,,622 LEARNING A COLOR ALGORITHM FROM EXAMPLES Anya C. Hurlbert and Tomaso A. Poggio Artificial Intelligence Laboratory and Department of Brain and Cognitive Sciences
1987,Generalization of Back propagation to Recurrent and Higher Order Neural Networks,,602 GENERALIZATION OF BACKPROPAGATION TO RECURRENT AND HIGHER ORDER NEURAL NETWORKS Fernando J.  Pineda Applied Physics Laboratory
1987,Neural Network Implementation Approaches for the Connection Machine,,127 Neural Network Implementation Approaches for the Connection Machine Nathan H. Brown
1987,On the Power of Neural Networks for Solving Hard Problems,,137 On the Power of Neural Networks for Solving Hard Problems J ehoshua Bruck Joseph W.  Goodman Information Systems Laboratory Departmen t  of Electrical Engineering Stanford University Stanford
1987,HOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE PIPELINED PROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS,,402 HOW THE PROCESSING CATFISH TRACKS ITS PREY: AN PIPELINED SYSTEM MAY DIRECT FORAGING VIA RETlCULOSPINAL NEURONS. INTERACTIVE Dept. of Cellular & Structural Biology
1987,Phasor Neural Networks,,584 PHASOR  NEURAL  NETVORKS Andr J.  Noest
1987,Computing Motion Using Resistive Networks,,422 COMPUTING  MOTION  USING  RESISTIVE  NETWORKS Christof Koch
1987,Experimental Demonstrations of Optical Neural Computers,,377 EXPERIMENTAL  DEMONSTRATIONS  OF OPTICAL NEURAL  COMPUTERS Ken  Hsu
1987,MURPHY: A Robot that Learns by Doing,,544 MURPHY: A Robot that Learns by Doing Bartlett W. Mel Center for Complex Systems Research University of Illinois 508 South Sixth Street Champaign
1987,SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENTS OF SERIES OF HUMAN BRAIN ELECTRIC FIELD MAPS,,467 SPONTANEOUS AND INFORMATION-TRIGGERED SEGMENTS OF SERIES OF HUMAN BRAIN ELECTRIC FIELD MAPS D. lehmann
1987,Simulations Suggest Information Processing Roles for the Diverse Currents in Hippocampal Neurons,,82 SIMULATIONS  SUGGEST INFORMATION PROCESSING ROLES FOR THE DIVERSE  CURRENTS  IN HIPPOCAMPAL NEURONS Lyle J.  Borg-Graham Harvard-MIT Division of Health Sciences and Technology and Center for  Biological Information Processing
1987,An Artificial Neural Network for Spatio-Temporal Bipolar Patterns: Application to Phoneme Classification,,31 AN  ARTIFICIAL NEURAL NETWORK FOR SPATIO(cid:173)TEMPORAL BIPOLAR PATTERNS:  APPLICATION TO PHONEME CLASSIFICATION Toshiteru  Homma Les E.  Atlas Robert J.  Marks II Interactive Systems Design Laboratory Department of Electrical Engineering
1987,Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems,,693 Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems J. F. Shepanski and S. A. Macy TRW
1987,Correlational Strength and Computational Algebra of Synaptic Connections Between Neurons,,270 Correlational Strength and Computational Algebra of Synaptic Connections Between Neurons Eberhard E. Fetz Department of Physiology & Biophysics
1987,Static and Dynamic Error Propagation Networks with Application to Speech Coding,,632 STATIC AND DYNAMIC ERROR PROPAGATION NETWORKS WITH APPLICATION TO SPEECH CODING A J Robinson
1987,Schema for Motor Control Utilizing a Network Model of the Cerebellum,,367 SCHEMA I'OR  MOTOR  CONTROL OT ILl ZING  A  NETWORK  MODEL  01'  THE  CEREBELLUM Northwestern  University  Medical  School
1987,Distributed Neural Information Processing in the Vestibulo-Ocular System,,457 DISTRIBUTED NEURAL INFORMATION PROCESSING IN THE VESTIBULO-OCULAR SYSTEM Cliord Lau Oice of Naval Research Detach ment Pasadena
1987,Time-Sequential Self-Organization of Hierarchical Neural Networks,,709 TIME-SEQUENTIAL  SELF-ORGANIZATION  OF  HIERARCHICAL NEURAL  NETWORKS Ronald  H.  Silverman Cornell  University  Medical  College
1987,A Method for the Design of Stable Lateral Inhibition Networks that is Robust in the Presence of Circuit Parasitics,,860 A  METHOD  FOR  THE  DESIGN  OF  STABLE  LATERAL  INHIBITION NETWORKS  THAT  IS  ROBUST  IN  THE  PRESENCE OF  CIRCUIT  PARASITICS J.L.  WYATT
1987,Constrained Dierential Optimization,,612 Constrained  Dierential  Optimization John  C.  Platt Alan H.  Barr California Institute of Technology
1987,Encoding Geometric Invariances in Higher-Order Neural Networks,,301 ENCODING  GEOMETRIC  INVARIANCES  IN HIGHER-ORDER  NEURAL  NETWORKS Air  Force  Oice  of  Scientific  Research
1987,A Novel Net that Learns Sequential Decision Process,,760 A  NOVEL NET THAT LEARNS SEQUENTIAL DECISION PROCESS G.Z.  SUN
1987,Mathematical Analysis of Learning Behavior of Neuronal Models,,164 MATHEMATICAL ANALYSIS  OF LEARNING BEHAVIOR OF NEURONAL MODELS By JOHN  Y.  CHEUNG MASSOUD  OMIDVAR SCHOOL  OF  ELECTRICAL  ENGINEERING  AND  COMPUTER  SCIENCE UNIVERSITY  OF  OKLAHOMA NORMAN
1987,New Hardware for Massive Neural Networks,,201 NEW HARDWARE FOR MASSIVE NEURAL NETWORKS D.  D.  Coon and A.  G. U.  Perera Applied Technology Laboratory University of Pittsburgh Pittsburgh
1987,An Adaptive and Heterodyne Filtering Procedure for the Imaging of Moving Objects,,662 AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE FOR THE IMAGING OF MOVING OBJECTS F. H. Schuling
1987,Phase Transitions in Neural Networks,,192 PHASE  TRANSITIONS  IN  NEURAL  NETWORKS University  of  Wisconsin
1987,Using Neural Networks to Improve Cochlear Implant Speech Perception,,783 USING NEURAL NETWORKS TO IMPROVE COCHLEAR IMPLANT SPEECH PERCEPTION Manoel F.  Tenorio School  of Electrical Engineering Purdue University West Lafayette
1987,Self-Organization of Associative Database and Its Applications,,767 SELF-ORGANIZATION OF  ASSOCIATIVE DATABASE AND  ITS  APPLICATIONS Hisashi  Suzuki  and  Suguru Arimoto Osaka University
1987,Temporal Patterns of Activity in Neural Networks,,297 TEMPORAL PATTERNS OF ACTIVITY IN NEURAL NETWORKS Paolo Gaudiano Dept.  of Aerospace  Engineering Sciences
1987,High Order Neural Networks for Eicient Associative Memory Design,,233 HIGH ORDER NEURAL NETWORKS FOR EICIENT ASSOCIATIVE MEMORY DESIGN I.  GUYON·
1987,The Capacity of the Kanerva Associative Memory is Exponential,,184 THE  CAPACITY  OF  THE  KANERVA  ASSOCIATIVE  MEMORY  IS  EXPONENTIAL Stanford  University.  Stanford.  CA  94305 P.  A.  Choul ABSTRACT The  capacity  of  an  associative  memory  is  defined  as  the  maximum number  of  vords  that  can  be  stored  and  retrieved  reliably  by  an  address vithin  a  given  sphere  of  attraction.  It  is  shown  by  sphere  packing arguments  that  as  the  address  length  increases.  the  capacity  of  any associati ve  memory  is  limited  to  an  exponential  grovth  rate  of  1 - h2 ( 0). vhere  h2(0)  is  the  binary  entropy  function  in  bits.  and  0  is  the  radius of  the  sphere  of  attraction.  This  exponential  grovth  in  capacity  can actually  be  achieved  by  the  Kanerva  associative  memory.  if  its parameters  are  optimally  set .  Formulas  for  these  op.timal  values  are provided.  The  exponential  grovth  in  capacity  for  the  Kanerva associative  memory  contrasts  sharply  vith  the  sub-linear  grovth  in capacity  for  the  Hopfield  associative  memory. ASSOCIATIVE  MEMORY  AND  ITS  CAPACITY Our  model  of  an  associative  memory  is  the  folloving.  Let  ()(
1987,The Sigmoid Nonlinearity in Prepyriform Cortex,,242 THE SIGMOID NONLINEARITY IN PREPYRIFORM CORTEX Frank H.  Eeckman University of California
1987,Probabilistic Characterization of Neural Model Computations,,310 PROBABILISTIC CHARACTERIZATION OF NEURAL MODEL COMPUTATIONS Richard M. Golden t University of Pittsburgh
1987,Learning in Networks of Nondeterministic Adaptive Logic Elements,,840 LEARNING IN NETWORKS OF NONDETERMINISTIC ADAPTIVE LOGIC ELEMENTS Richard  C.  Windecker* AT&T Bell Laboratories
1987,HIGH DENSITY ASSOCIATIVE MEMORIES,,HIGH DENSITY ASSOCIATIVE MEMORIES! 211 Information Systems Laboratory
1987,A Mean Field Theory of Layer IV of Visual Cortex and Its Application to Artificial Neural Networks,,683 A MEAN FIELD THEORY OF LAYER IV OF VISUAL CORTEX AND ITS  APPLICATION TO ARTIFICIAL NEURAL NETWORKS* Christopher  L.  Scofield Center  for  Neural  Science  and  Physics  Department Brown  University Providence
1987,Neural Networks for Template Matching: Application to Real-Time Classification of the Action Potentials of Real Neurons,,NEURAL  NETWORKS  FOR  TEMPLATE MATCHING: APPLICATION  TO  REAL-TIME  CLASSIFICATION OF  THE  ACTION  POTENTIALS  OF  REAL  NEURONS 103 Yiu-fai  Wongt
1987,Capacity for Patterns and Sequences in Kanerva's SDM as Compared to Other Associative Memory Models,,412 CAPACITY FOR PATTERNS AND  SEQUENCES IN  KANERVA'S SDM AS  COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS James  O.  Keeler Chemistry Department
1987,The Connectivity Analysis of Simple Association,,338 The Connectivity Analysis of Simple Association - or-How Many Connections Do You Need! Dan Hammerstrom * Oregon Graduate Center
1987,Performance Measures for Associative Memories that Learn and Forget,,432 Performance Measures for Associative Memories that Learn and Forget Anthony /(uh Department of Electrical  Engineering University  of Hawaii  at Manoa Honolulu HI
1987,Centric Models of the Orientation Map in Primary Visual Cortex,,62 Centric Models of the Orientation Map in Primary Visual Cortex Department of Computer Science
1987,A Computer Simulation of Olfactory Cortex with Functional Implications for Storage and Retrieval of Olfactory Information,,114 A Computer Simulation of Olfactory Cortex With Functional Implications for Storage and Retrieval of Olfactory Information Matthew A. Wilson and James M. Bower Computation and Neural Systems Program Division of Biology
1987,Towards an Organizing Principle for a Layered Perceptual Network,,485 TOWARDS AN  ORGANIZING PRINCIPLE FOR A LAYERED PERCEPTUAL NETWORK IBM Thomas J.  Watson Research Center
1987,A Trellis-Structured Neural Network,,592 A Trellis-Structured Neural Network* Thomas Petschet and Bradley W. Dickinson Princeton University
1987,Supervised Learning of Probability Distributions by Neural Networks,,52 Supervised Learning of Probability Distributions by Neural Networks Eric B. Baum Jet Propulsion Laboratory
1987,Stochastic Learning Networks and their Electronic Implementation,,9 Stochastic Learning Networks and their Electronic Implementation Joshua Alspector*. Robert B. Allen. Victor Hut. and Srinagesh Satyanarayanat Bell Communications Research. Morristown. NJ  01960 We describe a family  of learning algorithms that operate on a recurrent
1987,Connecting to the Past,,505 CONNECTING TO THE PAST Bruce  A.  MacDonald
1987,PARTITIONING OF SENSORY DATA BY A CORTICAL NETWORK,,317 PARTITIONING OF SENSORY DATA BY A CORTICAL NETWORK1 Richard Granger
1987,A Dynamical Approach to Temporal Pattern Processing,,750 A DYNAMICAL APPROACH TO TEMPORAL PATTERN PROCESSING W. Scott Stornetta Stanford University
1987,Minkowski-r Back-Propagation: Learning in Connectionist Models with Non-Euclidian Error Signals,,348 Minkowski-r Back-Propaaation:  Learnine in Connectionist Models with Non-Euclidian Error Silllais Stephen Jose Hanson and David J. Burr Bell Communications Research Morristown
1987,Analysis and Comparison of Dierent Learning Algorithms for Pattern Association Problems,,72 ANALYSIS AND COMPARISON OF DIERENT LEARNING ALGORITHMS FOR PATTERN ASSOCIATION PROBLEMS J. Bernasconi Brown Boveri Research Center CH-S40S Baden
1988,Neural Control of Sensory Acquisition: The Vestibulo-Ocular Reflex,,410 NEURAL CONTROL OF SENSORY ACQUISITION: THE VESTIBULO-OCULAR REFLEX. Michael G. Paulin
1988,Modeling the Olfactory Bulb - Coupled Nonlinear Oscillators,,402 MODELING  THE  OLFACTORY BULB - COUPLED NONLINEAR OSCILLATORS Zhaoping Lit J.  J.  Hopfield· t  Division of Physics
1988,Eicient Parallel Learning Algorithms for Neural Networks,,40 EICIENT PARALLEL LEARNING ALGORITHMS FOR NEURAL NETWORKS Alan H. Kramer and A. Sangiovanni-Vincentelli Department of EECS U .C. Berkeley Berkeley
1988,The Boltzmann Perceptron Network: A Multi-Layered Feed-Forward Network Equivalent to the Boltzmann Machine,,116 THE BOLTZMANN PERCEPTRON NETWORK: A MULTI-LAYERED FEED-FORWARD NETWORK EQUIVALENT TO THE BOLTZMANN MACHINE Eyal Yair  and  Allen Gersho Center for Infonnation Processing Research Department of Electrical &  Computer Engineering University of California
1988,Neural Networks that Learn to Discriminate Similar Kanji Characters,,332 NEURAL NETWORKS THAT LEARN TO DISCRIMINATE SIMILAR KANJI  CHARACTERS Yoshihiro  Morl Kazuhiko  Yokosawa ATR  Auditory  and  Visual  Perception  Research  Laboratories 2-1-61  Shiromi  Higashiku  Osaka  540  Japan ABSTRACT is to network is  applied feed-forward two  new  methods  are  utilized characters.  Using a learning  algorithm.  a the  problem  of b a c  k three(cid:173)A  neural  network recognizing  Kanji propagation  network layered. trained recognize  similar  handwritten  Kanji  characters. addition. training  eective.  The higher analysis  of  connection  weights  showed the  hierarchical networks  can  discern Kanji  characters.  This  strategy  of makes  high results eective  for  Kanji  character  recognition. to In to  make recognition  accuracy  was that  of  conventional  methods.  An that trained structure  of trained  networks recognition  accuracy  possible.  Our very that  neural  networks suggest than are 1  INTRODUCTION these  networks  has  been  better  than Neural  networks  are  applied  to  recognition  tasks  in  many  fields. the  field  of  letter  recognition.  net work s with  good  results.  In have  been  made  which  recognize  hand-written  digits [Burr  1986] 1988].  The and  complex  printed  Chinese that  of performance  of conventional  methods.  However. still large  number  of rudimentary  when  we  consider  not  only in  hand-written Kanji  characters.  but characters.  We  are  aiming that recognizes in  Japan. Since  it  is  diicult  for  a  single  network  to  discriminate  3000 characters.  our  plan by the  3000  Kanji  characters  commonly  used large-scale  network the involved the  distortion to  create  a to  make  a large-scale characters network results these [Ho are is Neural Networks that Learn Kanji Characters 333 assembling  many  smaller  ones  that  would  each  be  responsible  for recognizing  only  a small  number  of  characters. There  are  two  issues  concerning  implementation  of  such  a scale  network  :  the  ability  of  individual  networks.  and  organizing the  networks.  As  a  first  step.  the  ability  of  a  small  network  to discriminate  similar  Kanji  characters  was investigated.  We  found learning  speed  and  performance  of  networks  are  highly that influenced  by  environment the  order.  number. and  repetition  of  training  samples).  New  methods  of  teaching  the environment  are  utilized  to  make learning  eective. instance. large(cid:173)the (for 2  NEW TYPES  OF TEACHERS 2.1  PROBLEMS  OF  BACKPROPAGATION learning algorithm  only teaches The  Backpropagation(BP) the correct  answers  [Rumelhart  1986].  BP  does  not  care  about recognition  rate  of  each  category.  If  we  use  ordinary  BP in  a if  there  are  both  easy  and situation  of  limited  resources.  and diicult  categories  to learn  in  the  training  set.  what  happens  is that  the  easier  category  uses  up  most  of  the  resources  in  the  early stages  of  training the  diicult category  to  learn  should  get  more  resources.  This  weakness  of  BP makes (Figure  1).  Yet.  for  eiciency. learning  time  longer. the learning  procedures the  real Two  new  methods  are  used isolation. world. There  is  also  a  learning  environment.  It  is  therefore  natural.  and even  necessary. incorporate environmental to  avoid (human)  do  not  exist this  problem.  In in teaching  methods to  devise factors. that 334 Morl and Yokosawa Separation  by  BP Figure  1.  Easily  Learned  Category Ideal  Separation Takes  more  Resources Environment (The  feature  space  of  samples) Learning Procedur Category Back  Propagation Figure  2. Two  New  methods Neural Networks that Learn Kanji Characters 335 2.2  FIRST  METHOD  (REVIEW  METHOD) tracks is  focused  on  categories the  performance  for  each  category.  At  first
1988,Computer Modeling of Associative Learning,,COMPUTER  MODELING  OF  ASSOCIATIVE  LEARNING DANIEL  L.  ALKON' FRANCIS  QUEK2a THOMAS  P.  VOGL2b 419 1.  Laboratory  for  Cellular  and  Molecular NeurobiologYt  NINCDS t  NIH t  Bethesda t  MD  20892 2.  Environmental  Research  Institute  of  Michigan a)  P.O.  Box  8G18 t  Ann  Arbor t  MI  48107 b)  1501  Wilson  Blvd. t  Suite  1105 t  Arlington t  VA  22209 INTRODUCTION learning in The  eort  is  des i gned Most  of  the  current  neural  networks  use  models  which  have only  tenuous  connections  to  the  biological  neural  systems on  which  they  purport  to  be  based t  and  negligible  input from  the  neuroscience/biophysics  communities.  This  paper describes  an  ongoing  eort  which  approaches  neural  net research  in  a  program  of  close  collaboration  of  neuros(cid:173)c i ent i sts  and  eng i neers. to elucidate  associative the  marine  snail Hermissenda  crassicornis t  in  which  Pavlovian  conditioning has  been  observed.  Learning  has  been  isolated  in  the  four neuron  network  at  the  convergence  of  the  v i sua 1  and vestibular  pathways this  animal t  and  biophysical changes t  specific  to  learning t  have  been  observed  in  the membrane  of  the  photoreceptor  B cell.  A basic  charging capacitance  model  of  a  neuron  is  used  and  enhanced  with biologically  plausible  mechanisms  that  are  necessary  to replicate  the  eect  of  learning  at  the  cellular  level. These  mechanisms  are  non-linear  and  are t  primarilYt instances  of  second  order  control  systems  (e.g. t  fatigue t modul at i on  of  membrane time  dependent rebound)t  but  also  include  shunting  and  random  background fi ri ng. The  output  of  the  model  of  the  four- neuron network  di sp 1 ays  changes in  the  temporal  vari at i on  of membrane  potential  similar  to  those  observed  in  electro(cid:173)physiological  measurements. res i stance t in 420 Alkon
1988,Links Between Markov Models and Multilayer Perceptrons,,502 LINKS BETWEEN MARKOV MODELS AND MULTILAYER PERCEPTRONS H. Bourlard t
1988,Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment,,107 SKELETONIZATION: A TECHNIQUE FOR TRIMMING THE FAT FROM A NETWORK VIA RELEVANCE ASSESSMENT Michael C. Mozer Paul Smolensky Department of Computer Science & Institute of Cognitive Science University of Colorado Boulder
1988,A Passive Shared Element Analog Electrical Cochlea,,662 A  PASSIVE  SHARED  ELEMENT  ANALOG ELECTRICAL  COCHLEA Joe Eisenberg Bioeng. Group U.C. Berkeley Edwin Lewis Dept Elect. Eng. U.C. Berkeley David Feld Dept. Elect. Eng. 207-30 Cory Hall U.C. Berkeley Berkeley
1988,Speech Production Using A Neural Network with a Cooperative Learning Mechanism,,232 SPEECH  PRODUCTION  USING  A  NEURAL NETWORK  WITH  A  COOPERATIVE LEARNING  MECHANISM International Institute for Advanced Study of Social Information Science
1988,Associative Learning via Inhibitory Search,,20 ASSOCIATIVE LEARNING VIA INHIBITORY SEARCH David H.  Ackley Bell  Communications Research Cognitive Science  Research Group ABSTRACT ALVIS is  a  reinforcement-based  connectionist  architecture  that learns  associative  maps  in  continuous  multidimensional  environ(cid:173)ments.  The  discovered  locations  of  positive  and  negative  rein(cid:173)forcements  are  recorded  in  do be  and  don't  be  subnetworks
1988,Performance of a Stochastic Learning Microchip,,748 Performance of a Stochastic Learning Microchip Joshua Alspector
1988,Song Learning in Birds,,795 SONG  LEARNING  IN  BIRDS M.  Konishi Division of Biology California Institute of Technology Birds  sing  to communicate.  Male  birds  use  song  to advertise their territories  and attract females.  Each  bird  species  has a  unique song or set of songs.  Song conveys both species  and  individual  identity.  In  most  species
1988,Modeling Small Oscillating Biological Networks in Analog VLSI,,384 MODELING  SMALL  OSCILLATING BIOLOGICAL NETWORKS IN ANALOG  VLSI Sylvie  Ryckebusch
1988,Comparing Biases for Minimal Network Construction with Back-Propagation,,177 COMPARING BIASES FOR MINIMAL NETWORK CONSTRUCTION WITH BACK-PROPAGATION Stephen Jo~ Hansont Lorien Y. Pratt Bell Communications Research Morristown. New Jersey 07960 New Brunswick. New Jersey 08903 Rutgers University ABSTRACT learning representations during Rumelhart (1987). has proposed a method for choosing minimal or simple in Back-propagation networks. This approach can be used to (a) dynamically select the number of hidden units. (b) construct a representation that is appropriate for the problem and (c) thus improve the generalization ability of Back-propagation networks. The method Rumelhart suggests involves adding penalty terms to the usual error function. In this paper we introduce Rumelhart·s minimal networks idea and compare two possible biases on the weight search space. These biases are compared in both simple counting problems and a speech recognition problem. In general. the constrained search does seem to minimize the number of hidden units required with an expected increase in local minima. INTRODUCTION Many supervised connectionist models use gradient descent in error to solve various kinds of tasks (Rumelhart. Hinton & Williams. 1986). However. such gradient descent methods tend to be .opportunistic and can solve problems in an arbitrary way dependent on starting point in weight space and peculiarities of the training set. For example. in Figure 1 we show a mesh problem which consists of a random distribution of exemplars from two categories. The spatial geometry of the categories impose a meshed or overlapping subset of the exemplars in the two dimensional feature space. As the meshed part of the categories increase the problem becomes more complex and must involve the combination of more linear cuts in feature space and consequently more nonlinear cuts for category separation. In the top left corner of Figure l(a). we show a mesh geometry requiring only three cuts for category separation. In the bottom center t Also member of Cognitive Science Laboratory
1988,What Size Net Gives Valid Generalization?,,81 WHAT SIZE  NET GIVES  VALID GENERALIZATION?* Eric B.  Baum Department of Physics Princeton University Princeton NJ 08540 David Haussler Computer and Information Science University of California Santa Cruz
1988,A Low-Power CMOS Circuit Which Emulates Temporal Electrical Properties of Neurons,,678 A LOW-POWER CMOS CIRCUIT WHICH EMULATES TEMWORALELECTIDCALPROPERTIES OF NEURONS Jack L. Meador and Clint S. Cole Electrical and Computer Engineering Dept. Washington State University Pullman WA. 99164-2752 ABSTRACf This  paper  describes  a  CMOS  artificial  neuron.  The  circuit  is directly  derived  from  the  voltage-gated  channel  model  of  neural membrane
1988,Linear Learning: Landscapes and Algorithms,,LINEAR LEARNING: LANDSCAPES  AND  ALGORITHMS 65 Pierre Baldi Jet  Propulsion Laboratory California Institute of Technology Pasadena
1988,Applications of Error Back-Propagation to Phonetic Classification,,206 APPLICATIONS OF ~RROR BACK-PROPAGATION TO PHONETIC CLASSIFICATION Hong C. Leung & Victor W. Zue Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology Cambridge
1988,An Analog Self-Organizing Neural Network Chip,,739 AN ANALOG SELF-ORGANIZING NEURAL NElWORK CHIP James R. Mann Sheldon Gilbert MIT Lincoln Laboratory 244 Wood Street Lexington
1988,A Bifurcation Theory Approach to the Programming of Periodic Attractors in Network Models of Olfactory Cortex,,A BIFURCATION THEORY APPROACH TO THE PROGRAMMING OF PERIODIC A TTRACTORS IN NETWORK MODELS OF OLFACTORY CORTEX 459 Bill  Baird Department  of  Biophysics U.C.  Berkeley ABSTRACT A  new  learning  algorithm  for  the  storage  of  static and  periodic  attractors  in  biologically  inspired recurrent  analog  neural  networks  is  introduced. For  a  network  of  n  nodes
1988,Heterogeneous Neural Networks for Adaptive Behavior in Dynamic Environments,,577 HETEROGENEOUS NEURAL NETWORKS FOR ADAPTIVE BEHAVIOR IN DYNAMIC ENVIRONMENTS Hillel J. Chiel Biology Dept. & CAISR CWRU Randall D. Beer Dept. of Computer Engineering and Science and Center for Automation and Intelligent Systems Research Case Western Reserve University Cleveland
1988,Programmable Analog Pulse-Firing Neural Networks,,PROGRAMMABLE ANALOG PULSE-FIRING NEURAL NETWORKS 671 Alan F.  Murray Dept.  of Elec.  Eng.
1988,An Analog VLSI Chip for Thin-Plate Surface Interpolation,,AN ANALOG VLSI CHIP FOR THIN-PLATE SURFACE INTERPOLATION 687 John G. Harris California Institute of Technology Computation and Neural Systeins Option
1988,Simulation and Measurement of the Electric Fields Generated by Weakly Electric Fish,,436 SIMULATION AND MEASUREMENT OF THE ELECTRIC FIELDS GENERATED BY WEAKLY ELECTRIC FISH Brian Rasnow1
1988,Training Multilayer Perceptrons with the Extended Kalman Algorithm,,TRAINING MULTILAYER PERCEPTRONS WITH THE EXTENDED KALMAN ALGORITHM 133 Sharad Singhal and Lance Wu Bell Communications Research
1988,An Electronic Photoreceptor Sensitive to Small Changes in Intensity,,720 AN ELECTRONIC PHOTORECEPTOR SENSITIVE TO SMALL CHANGES IN INTENSITY T. Delbriick and C. A. Mead 256-80 Computer Science California Institute of Technology Pasadena
1988,Training a 3-Node Neural Network is NP-Complete,,494 TRAINING A  3-NODE NEURAL NETWORK IS  NP-COMPLETE Avrim Blum' MIT Lab.  for  Computer Science Cambridge
1988,Automatic Local Annealing,,602 AUTOMATIC LOCAL ANNEALING Jared Leinbach Deparunent of Psychology Carnegie-Mellon University Pittsburgh
1988,Adaptive Neural Net Preprocessing for Signal Detection in Non-Gaussian Noise,,124 ADAPTIVE  NEURAL  NET  PREPROCESSING FOR SIGNAL DETECTION IN  NON-GAUSSIAN  NOISE1 Richard  P.  Lippmann  and  Paul Beckman MIT  Lincoln  Laboratory Lexington
1988,Learning the Solution to the Aperture Problem for Pattern Motion with a Hebb Rule,,468 LEARNING THE SOLUTION TO THE APERTURE PROBLEM FOR PATTERN MOTION WITH A HEBB RULE Martin I. Sereno Cognitive Science C-015 University of California
1988,GENESIS: A System for Simulating Neural Networks,,485 GENESIS: A SYSTEM FOR SIMULATING NEURAL NETWOfl.KS Matthew A. Wilson
1988,Neural Architecture,,794 NEURAL  ARCHITECTURE Valentino Braitenberg Max Planck Institute Federal Republic of Germany While  we  are  waiting for  the  ultimate  biophysics of cell  membranes and  synapses to be completed
1988,Learning by Choice of Internal Representations,,73 LEARNING  BY CHOICE OF INTERNAL REPRESENTATIONS Tal Grossman
1988,Adaptive Neural Networks Using MOS Charge Storage,,761 Adaptive Neural Networks  Using MOS  Charge Storage D.  B.  Schwartz 1
1988,Implications of Recursive Distributed Representations,,RECURSIVE DISTRIBUTED REPRESENTATIONS IMPLICATIONS OF 527 Jordan B.  Pollack Laboratory for A I Research Ohio State University Columbus
1988,Backpropagation and Its Application to Handwritten Signature Verification,,340 BACKPROPAGATION AND ITS APPLICATION TO HANDWRITTEN SIGNATURE VERIFICATION Dorothy A.  Mighell Electrical Eng.  Dept. Info.  Systems Lab Stanford University Stanford
1988,Theory of Self-Organization of Cortical Maps,,451 THEORY OF SELF-ORGANIZATION OF CORTICAL MAPS Fundamental Research Laboratorys
1988,An Adaptive Network That Learns Sequences of Transitions,,653 AN ADAPTIVE NETWORK THAT LEARNS SEQUENCES OF TRANSITIONS C. L. Winter Science Applications International Corporation 5151 East Broadway
1988,Dynamics of Analog Neural Networks with Time Delay,,568 DYNAMICS OF ANALOG NEURAL NETWORKS WITH TIME DELAY C.M. Marcus and RM. Westervelt Division of Applied Sciences and Department of Physics Harvard University
1988,On the K-Winners-Take-All Network,,634 ON THE K-WINNERS-TAKE-ALL NETWORK E.  Majani Jet Propulsion Laboratory California Institute of Technology R.  Erlanson
1988,Does the Neuron Learn like the Synapse?,,169 DOES THE NEURON LEARN LIKE THE SYNAPSE? RAOUL TAWEL Jet Propulsion Laboratory California Institute of Technology Pasadena
1988,Use of Multi-Layered Networks for Coding Speech with Phonetic Features,,224 USE  OF  MULTI-LAYERED  NETWORKS  FOR CODING  SPEECH  WITH  PHONETIC  FEATURES Yoshua Bengio
1988,Electronic Receptors for Tactile/Haptic Sensing,,ELECTRONIC  RECEPTORS  FOR  TACTILE/HAPTIC·  SENSING 785 Electrical and Computer Engineering The Johns Hopkins University Andreas G. Andreou Baltimore
1988,A Programmable Analog Neural Computer and Simulator,,712 A PROGRAMMABLE ANALOG NEURAL COMPUTER AND SIMULATOR Paul Mueller*
1988,An Information Theoretic Approach to Rule-Based Connectionist Expert Systems,,256 AN INFORMATION  THEORETIC APPROACH TO RULE-BASED  CONNECTIONIST EXPERT SYSTEMS Rodney  M.  Goodman
1988,A Connectionist Expert System that Actually Works,,248 A CONNECTIONIST EXPERT SYSTEM THAT ACTUALLY WORKS Gary  Bradshaw Psychology Richard  Fozzard Computer Science LouisCeci Computer Science University of Colorado Boulder
1988,Cricket Wind Detection,,802 CRICKET WIND  DETECTION John  P.  Miller Neurobiology  Group
1988,ALVINN: An Autonomous Land Vehicle in a Neural Network,,ALVINN: AN AUTONOMOUS LAND VEHICLE IN A NEURAL NETWORK 305 Dean A. Pomerleau Computer Science Department Carnegie Mellon University Pittsburgh
1988,Fast Learning in Multi-Resolution Hierarchies,,29 FAST LEARNING IN MULTI-RESOLUTION HIERARCHIES Yale Computer Science
1988,Mapping Classifier Systems Into Neural Networks,,49 Mapping Classifier Systems Into  Neural  Networks Lawrence  Davis BBN Laboratories BBN Systems and Technologies Corporation 10 Moulton Street Cambridge
1988,A Network for Image Segmentation Using Color,,297 A NETWORK FOR IMAGE SEGMENTATION USING COLOR Anya Hurlbert and Tomaso Poggio Center for Biological Information Processing at Whitaker College Department of Brain and Cognitive Science and the MIT AI Laboratory Cambridge
1988,A Model for Resolution Enhancement (Hyperacuity) in Sensory Representation,,444 A MODEL FOR RESOLUTION ENHANCEMENT (HYPERACUITY)  IN  SENSORY REPRESENTATION Jun  Zhang and John  P.  Miller Neurobiology  Group
1988,Temporal Representations in a Connectionist Speech System,,240 TEMPORAL REPRESENTATIONS  IN A CONNECTIONIST SPEECH  SYSTEM Erich  J.  Smythe 207  Greenmanville  Ave
1988,Neural Network Star Pattern Recognition for Spacecraft Attitude Determination and Control,,314 NEURAL NETWORK STAR PATTERN RECOGNITION  FOR  SPACECRAFT ATTITUDE DETERMINATION AND CONTROL Phillip Alvelda
1988,A Massively Parallel Self-Tuning Context-Free Parser,,A MASSIVELY PARALLEL SELF-TUNING CONTEXT-FREE PARSER! 537 Eugene Santos Jr. Department of Computer Science Brown  University Box 1910
1988,Neural Net Receivers in Multiple Access-Communications,,272 NEURAL NET RECEIVERS IN MULTIPLE-ACCESS COMMUNICATIONS Bernd-Peter Paris
1988,A Computationally Robust Anatomical Model for Retinal Directional Selectivity,,477 A  COMPUTATIONA.LLY ROBUST ANATOlVIICAL  MODEL  FOR RETIN.AL DIRECTIONAL SELECTI\lITY Norberto  M.  Grzywacz Center BioI.  Inf.  Processing MIT
1988,Statistical Prediction with Kanerva's Sparse Distributed Memory,,586 STATISTICAL PREDICTION WITH KANERVA'S SPARSE DISTRmUTED MEMORY David Rogers Research Institute for Advanced Computer Science MS 230-5
1988,Learning Sequential Structure in Simple Recurrent Networks,,643 LEARNING SEQUENTIAL STRUCTURE IN SIMPLE RECURRENT NETWORKS David Servan-Schreiber. Axel Cleeremans. and James L. McClelland Departtnents of Computer Science and Psycholgy Carnegie Mellon University Pittsburgh
1988,A Back-Propagation Algorithm with Optimal Use of Hidden Units,,A BACK-PROPAGATION ALGORITHM WITH OPTIMAL USE OF HIDDEN UNITS 519 Yves  Chauvin Thomson-CSF
1988,GEMINI: Gradient Estimation Through Matrix Inversion After Noise Injection,,GEMINI: GRADIENT ESTIMATION THROUGH MATRIX INVERSION AFTER NOISE INJECTION 141 Yann Le Cun 1 Conrad C. Galland and Georey E. Hinton Department of Computer Science University of Toronto 10 King's College Rd Toronto
1988,A Self-Learning Neural Network,,769 A SELF-LEARNING NEURAL NETWORK A. Hartstein and R. H. Koch IBM - Thomas J. Watson Research Center Yorktown Heights
1988,Neural Networks for Model Matching and Perceptual Organization,,618 NEURAL NETWORKS FOR MODEL MATCHING AND PERCEPTUAL ORGANIZATION Gene Gindi EE Department Yale University New Haven
1988,Neuronal Maps for Sensory-Motor Control in the Barn Owl,,366 NEURONAL MAPS FOR SENSORY -MOTOR CONTROL IN THE BARN OWL C.D. Spence
1988,Performance of Synthetic Neural Network Classification of Noisy Radar Signals,,281 PERFORMANCE OF  SYNTHETIC  NEURAL NETWORK  CLASSIFICATION  OF  NOISY RADAR SIGNALS S. C.  Ahalt F. D.  Garber I. Jouny A.  K . Krishnamurthy Department of Electrical Engineering The Ohio State University
1988,Connectionist Learning of Expert Preferences by Comparison Training,,99 Connectionist  Learning of Expert  Preferences  by Comparison  Training Gerald  Tesauro IBl\f Thomas.1.  '''atson  Rcsearc11  Centcr PO  Box  704
1988,Winner-Take-All Networks of O(N) Complexity,,703 WINNER-TAKE-ALL NETWORKS OF O(N) COMPLEXITY J. Lazzaro
1988,Neural Network Recognizer for Hand-Written Zip Code Digits,,323 NEURAL NETWORK RECOGNIZER FOR HAND-WRITTEN ZIP CODE DIGITS J. S. Denker
1988,Analog Implementation of Shunting Neural Networks,,ANALOG  IMPLEMENTATION  OF  SHUNTING NEURAL  NETWORKS 695 Bahram Nabet
1988,Range Image Restoration Using Mean Field Annealing,,594 Range Image Restoration using Mean Field Annealing Gri L.  Bilbro Wesley  E.  Snyder Center for  Communications and Signal  Processing North  Carolina State  University Raleigh
1988,Analyzing the Energy Landscapes of Distributed Winner-Take-All Networks,,626 ANALYZING THE ENERGY LANDSCAPES OF  DISTRIBUTED WINNER-TAKE-ALL  NETWORKS David S.  Touretzky School of Computer Science Carnegie Mellon University Pittsburgh
1988,Neural Approach for TV Image Compression Using a Hopfield Type Network,,264 NEURAL APPROACH FOR TV IMAGE COMPRESSION USING A HOPFIELD TYPE NETWORK Jean-Bernard THEETEN Laboratoire d'Electronique et de Physique Appliquee * Martine NAILLON 3 Avenue DESCARTES
1988,Speech Recognition: Statistical and Neural Information Processing Approaches,,796 SPEECH  RECOGNITION:  STATISTICAL AND NEURAL  INFORMATION PROCESSING APPROACHES John S.  Bridle Speech  Research Unit and National Electronics Research Initiative in Pattern Recognition Royal Signals and  Radar Establishment Malvern UK Automatic Speech Recognition (ASR) is an artificial perception problem:  the input is  raw
1988,Convergence and Pattern-Stabilization in the Boltzmann Machine,,511 CONVERGENCE AND PATTERN STABILIZATION IN THE BOLTZMANN MACHINE MosheKam Roger Cheng Dept. of Electrical and Computer Eng. Drexel University
1988,Models of Ocular Dominance Column Formation: Analytical and Computational Results,,LINEAR LEARNING: LANDSCAPES  AND  ALGORITHMS 65 Pierre Baldi Jet  Propulsion Laboratory California Institute of Technology Pasadena
1988,Digital Realisation of Self-Organising Maps,,728 DIGITAL REALISATION OF SELF-ORGANISING MAPS Nigel M. Allinson M~rtin J. Johnson Department of Electronics University of York York Y015DD England ABSTRACT Kevin J. Moon The method is presented. A digital realisation of two-dimensional self-organising feature maps is based on subspace technique. Weight vector classification using an n-tuple approximation and orthogonal projections to produce a winner(cid:173)takes-all network are also discussed. Over one million eective binary weights can be applied in 25ms using a conventional microcomputer. Details of a number of image recognition tasks
1988,Further Explorations in Visually-Guided Reaching: Making MURPHY Smarter,,348 Further Explorations in Visually-Guided Reaching:  Making  MURPHY Smarter Bartlett W.  Mel Center for  Complex Systems Research Beckman Institute
1988,Scaling and Generalization in Neural Networks: A Case Study,,160 SCALING  AND  GENERALIZATION IN NEURAL  NETWORKS:  A  CASE STUDY Subutai Ahmad Center for  Complex Systems  Research University of Illinois at Urbana-Champaign 508  S.  6th St.
1988,A Model of Neural Oscillator for a Unified Submodule,,560 A MODEL OF NEURAL OSCILLATOR FOR A UNIFIED SUEt10DULE A.B.Kirillov
1988,An Optimality Principle for Unsupervised Learning,,11 AN  OPTIMALITY PRINCIPLE FOR UNSUPERVISED LEARNING Terence D.  Sanger MIT AI  Laboratory
1988,Neural Analog Diusion-Enhancement Layer and Spatio-Temporal Grouping in Early Vision,,289 NEURAL ANALOG DIUSION-ENHANCEMENT LAYER AND SPATIO-TEMPORAL GROUPING IN EARLY VISION Allen M. Waxman·
1988,Optimization by Mean Field Annealing,,OPTIMIZATION BY MEAN FIELD ANNEALING 91 Gri Bilbro ECE Dept. NCSU Raleigh
1988,An Application of the Principle of Maximum Information Preservation to Linear Systems,,186 AN APPLICATION OF THE PRINCIPLE OF MAXIMUM INFORMATION PRESERVATION TO LINEAR SYSTEMS IBM T. J.  Watson Research Center
1988,Spreading Activation over Distributed Microfeatures,,553 SPREADING ACTIVATION OVER DISTRIBUTED MICROFEATURES * James Hendler Depart.ment
1988,Consonant Recognition by Modular Construction of Large Phonemic Time-Delay Neural Networks,,Consonant Recognition by Modular Construction of Large Phonemic Time-Delay Neural Networks 215 Alex Waibel Carnegie-Mellon University Pittsburgh
1988,Constraints on Adaptive Networks for Modeling Human Generalization,,2 CONSTRAINTS ON ADAPTIVE NETWORKS FOR MODELING HUMAN GENERALIZATION M. Pavel Mark A. Gluck Van Henkle Departm£1Il of Psychology Stanford University Stanford. CA 94305 ABSTRACT The potential of adaptive  networks  to learn categorization rules and to model  human  performance  is  studied  by  comparing  how  natural  and artificial systems respond to new inputs
1988,Self Organizing Neural Networks for the Identification Problem,,57 Self  Organizing  Neural  Networks  for  the Identification  Problem Manoel Fernando Tenorio School of Electrical Engineering Purdue University VV. Lafayette
1988,Learning with Temporal Derivatives in Pulse-Coded Neuronal Systems,,LEARNING WITH TEMPORAL DERIVATIVES IN PULSE-CODED NEURONAL SYSTEMS Mark Gluck David B. Parker Eric S. Reifsnider 195 Department of Psychology Stanford University Stanford
1988,Using Backpropagation with Temporal Windows to Learn the Dynamics of the CMU Direct-Drive Arm II,,356 USING BACKPROPAGATION WITH TEMPORAL WINDOWS TO LEARN THE DYNAMICS OF THE CMU DIRECT-DRIVE ARM II K.  Y.  Goldberg and B.  A.  Pearlmutter School of Computer Science Carnegie Mellon University Pittsburgh
1988,Storing Covariance by the Associative Long-Term Potentiation and Depression of Synaptic Strengths in the Hippocampus,,394 STORING COVARIANCE BY THE ASSOCIATIVE LONG·TERM POTENTIATION AND DEPRESSION OF SYNAPTIC STRENGTHS IN THE HIPPOCAMPUS Patric K. Stanton· and Terrence J. Sejnowskit Department of Biophysics Johns Hopkins University Baltimore
1988,Fixed Point Analysis for Recurrent Networks,,149 FIXED POINT ANALYSIS FOR RECURRENT NETWORKS Mary B. Ottaway Dana H. Ballard Patrice Y. Simard Dept. of Computer Science University of Rochester Rochester NY 14627 ABSTRACT This paper provides a systematic analysis of the recurrent backpropaga(cid:173)tion (RBP) algorithm
1989,Comparing the Performance of Connectionist and Statistical Classifiers on an Image Segmentation Problem,,614 Gish and Blanz Comparing  the  Performance  of Connectionist and  Statistical  Classifiers  on  an  Image Segmentation  Problem Sheri  L.  Gish  w.  E.  Blanz IBM  Almaden  Research  Center 650 Harry Road San Jose
1989,Analog Circuits for Constrained Optimization,,Analog Circuits for  Constrained Optimization 777 A nalog  Circuits for  Constrained  Optimization John  C.  Platt  1 Computer Science  Department
1989,Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters,,Training Stochastic Model Recognition Algorithms 211 Training  Stochastic  Model  Recognition Algorithms  as  Networks  can  lead  to  Maximum Mutual Information  Estimation  of Parameters John s. Bridle Royal Signals and  Radar Establishment Great  Malvern Worcs. UK WR143PS ABSTRACT One  of the  attractions  of neural  network  approaches  to  pattern recognition  is  the  use  of a  discrimination-based  training  method. We  show  that once  we  have  modified  the  output  layer  of a  multi(cid:173)layer perceptron to provide mathematically correct  probability dis(cid:173)tributions
1989,Can Simple Cells Learn Curves? A Hebbian Model in a Structured Environment,,Can Simple Cells Learn Curves?  A Hebbian Model in a Structured Environment 125 Can Simple Cells Learn Curves?  A Hebbian Model in a  Structured Environment William R.  Softky Daniel M.  Kammen Divisions of Biology and Physics Divisions of Biology and  Engineering 103-33 Caltech Pasadena
1989,Development and Regeneration of Eye-Brain Maps: A Computational Model,,92 Cowan and Friedman Development and Regeneration of Eye-Brain Maps: A  Computational Model J.D. Cowan  and A.E. Friedman Department of Mathematics. Committee on Neurobiology. and Brain Research Institute. The University of Chicago. 5734  S. Univ. Ave .• Chicago. Illinois 60637 ABSTRACT We outline a computational model  of the development and regenera(cid:173)tion of specific eye-brain circuits. The model comprises a self-organiz(cid:173)ing map-forming network which uses local Hebb rules. constrained by molecular markers.  Various  simulations of the development of eye(cid:173)brain maps in fish and frogs are described. 1  INTRODUCTION The brain is a biological computer of immense complexity comprising highly specialized neurons and neural circuits.  Such neurons  are interconnected with  high specificity  in many regions of the brain. if not in all. There are also many observations which indicate that there is also considerable circuit plasticity.  Both specificity and plasticity are found in  the development and regeneration  of eye-brain connections in  vertebrates.  Sperry (1944) frrst demonstrated specificity in the regeneration of eye-brain connections in frogs following  optic nerve section and eye rotation
1989,Predicting Weather Using a Genetic Memory: A Combination of Kanerva's Sparse Distributed Memory with Holland's Genetic Algorithms,,Predicting Weather Using a Genetic Memory 455 Predicting Weather Using a Genetic Memory: a Combi(cid:173)nation of Kanerva's Sparse Distributed Memory  with Holland's Genetic Algorithms David Rogers Research Institute for Advanced Computer Science MS 230-5
1989,Neural Network Analysis of Distributed Representations of Dynamical Sensory-Motor Transformations in the Leech,,28 Lockery t Fang and Sejnowski Neu.·al Network Analysis of Distributed Representations of Dynamical Sensory-Motor rrransformations in the Leech Shawn R. LockerYt Van Fangt and Terrence J. Sejnowski Computational Neurobiology Laboratory Salk Institute for Biological Studies Box 85800
1989,A Computer Modeling Approach to Understanding the Inferior Olive and Its Relationships to the Cerebellar Cortex in Rats,,A Computer Modeling Approach to Understanding 117 A computer modeling approach to  understanding the inferior olive and its relationship to the cerebellar cortex in rats Maurice Lee and James M. Bower Computation and Neural Systems Program California Institute of Technology Pasadena
1989,Generalization and Scaling in Reinforcement Learning,,550 Ackley and Littman Generalization  and  scaling  in  reinforcement learning David H.  Ackley Michael L.  Littman Cognitive Science  Research Group Bellcore Morristown
1989,Neural Network Weight Matrix Synthesis Using Optimal Control Techniques,,348 Farotimi
1989,Collective Oscillations in the Visual Cortex,,76 Kammen
1989,Neural Networks: The Early Days,,828 Cowan Neural networks: the early days J.D. Cowan Department of Mathematics
1989,Operational Fault Tolerance of CMAC Networks,,340 Carter
1989,Eects of Firing Synchrony on Signal Propagation in Layered Networks,,Eects of Firing Synchrony on Signal Propagation in Layered Networks 141 Eects  of Firing  Synchrony  on  Signal Propagation in  Layered Networks G. T.  Kenyon
1989,Acoustic-Imaging Computations by Echolocating Bats: Unification of Diversely-Represented Stimulus Features into Whole Images,,2 Simmons Acoustic-Imaging  Computations  by  Echolocating Bats: Unification  of Diversely-Represented  Stimulus Features  into  Whole  Images. James A. Simmons Department of Psychology and Section of Neurobiology
1989,Time Dependent Adaptive Neural Networks,,710 Pineda Time DependentAdaptive Neural Networks Fernando J. Pineda Center for Microelectronics Technology Jet Propulsion Laboratory California Institute of Technology Pasadena
1989,Neural Network Visualization,,Neural Network Visualization 465 NEURAL  NETWORK  VISUALIZATION Jakub Wejchert Gerald Tesauro IB M  Research T.J.  Watson Research Center Yorktown Heights NY  10598 ABSTRACT We  have developed graphics  to visualize  static and dynamic infor(cid:173)mation in layered neural network learning systems.  Emphasis  was placed  on  creating new  visuals  that  make  use  of spatial arrange(cid:173)ments
1989,Discovering the Structure of a Reactive Environment by Exploration,,Discovering the Structure of a Reactive Environment by Exploration 439 Discovering the Structure of a Reactive Environment by Exploration Michael C. Mozer Department of Computer Science and Institute of Cognitive Science University of Colorado Boulder
1989,A Self-organizing Associative Memory System for Control Applications,,332 Hormel A  Sell-organizing Associative Memory System  lor Control Applications Michael  Bormel Department  of  Control  Theory  and  Robotics Technical  University  of  Darmstadt Schlossgraben  1 6100  Darmstadt/W.-Ger.any ABSTRACT The  CHAC  storage  scheme  has  been  used  as  a  basis for  a  software  implementation  of  an  associative .emory  system  AHS
1989,Complexity of Finite Precision Neural Network Classifier,,668 Dembo
1989,Neuronal Group Selection Theory: A Grounding in Robotics,,308 Donnett and Smithers Neuronal  Group  Selection  Theory: A  Grounding in  Robotics Jim Donnett and Tim Smithers Department of Artificial Intelligence University of Edinburgh 5  Forrest Hill Edinburgh  EH12QL SCOTLAND ABSTRACT In this paper
1989,Dimensionality Reduction and Prior Knowledge in E-Set Recognition,,178 Lang and Hinton Dimensionality Reduction and Prior Knowledge  in E-set Recognition Kevin J. Lang1 Computer Science Dept. Carnegie Mellon University Pittsburgh
1989,A self-organizing multiple-view representation of 3D objects,,274 WeinshalI
1989,Associative Memory in a Simple Model of Oscillating Cortex,,68 Baird Associative  Memory  in  a  Simple  Model  of Oscillating  Cortex Bill Baird Dept Molecular and Cell  Biology
1989,Adjoint Operator Algorithms for Faster Learning in Dynamical Neural Networks,,498 Barben
1989,Computer Simulation of Oscillatory Behavior in Cerebral Cortical Networks,,84  Wilson and Bower Computer  Simulation  of Oscillatory  Behavior in  Cerebral  Cortical Networks Matthew A.  Wilson and James M.  Bower! Computation and  Neural  Systems Program Division of Biology
1989,Coupled Markov Random Fields and Mean Field Theory,,660 Geiger and Girosi Coupled  Markov  Random  Fields  and Mean  Field  Theory Davi Geigerl Artificial Intelligence Laboratory
1989,Pulse-Firing Neural Chips for Hundreds of Neurons,,Pulse-Firing Neural Chips for Hundreds of Neurons 785 PULSE-FIRING NEURAL CIDPS FOR HUNDREDS OF NEURONS Michael Brownlow Lionel Tarassenko Dept.  Eng.  Science Univ.  of Oxford Oxford  OX1  3PJ Alan F.  Murray Dept.  Electrical Eng. Univ.  of Edinburgh Mayfield  Road Edinburgh EH9 3JL Alister Hamilton II  Song Han(l) H. Martin Reekie Dept.  Electrical Eng. U niv.  of Edinburgh ABSTRACT We  announce  new  CMOS  synapse  circuits  using  only  three and four  MOSFETsisynapse.  Neural states are asynchronous pulse  streams
1989,Rule Representations in a Connectionist Chunker,,Rule Representations in a Connectionist Chunker 431 Rule Representations in  a Connectionist Chunker David S.  Touretzky  Gillette Elvgren m School of Computer Science Carnegie Mellon University Pittsburgh
1989,A Neural Network for Real-Time Signal Processing,,248  MalkofT A Neural Network for Real-Time Signal Processing Donald B.  Malko General Electric  /  Advanced Technology Laboratories Moorestown Corporate Center Building  145-2
1989,Speaker Independent Speech Recognition with Neural Networks and Speech Knowledge,,218 Bengio
1989,Analytic Solutions to the Formation of Feature-Analysing Cells of a Three-Layer Feedforward Visual Information Processing Neural Net,,160 Tang Analytic Solutions to the Formation of Feature-Analysing Cells of a Three-Layer Feedforward Visual Information Processing Neural Net Microelectronics and Computer Technology Corporation D.S. Tang 3500 West Balcones Center Drive Austin
1989,An Analog VLSI Model of Adaptation in the Vestibulo-Ocular Reflex,,742 DeWeerth and Mead An Analog  VLSI Model  of Adaptation in the  Vestibulo-Ocular  Reflex Stephen P.  DeWeerth and  Carver A.  Mead California Institute of Technology Pasadena
1989,A Reconfigurable Analog VLSI Neural Network Chip,,758 Satyanarayana
1989,Handwritten Digit Recognition with a Back-Propagation Network,,396 Le Cun
1989,Digital-Analog Hybrid Synapse Chips for Electronic Neural Networks,,Digital-Analog Hybrid Synapse Chips for Electronic Neural Networks 769 Digital-Analog Hybrid Synapse Chips for Electronic Neural Networks A  Moopenn
1989,Computational Eiciency: A Common Organizing Principle for Parallel Computer Maps and Brain Maps?,,60 Nelson and Bower Computational Eiciency: A  Common  Organizing  Principle  for Parallel  Computer  Maps  and  Brain  Maps? Mark E.  Nelson  James  M.  Bower Computation and Neural Systems Program Division of Biology
1989,A Cost Function for Internal Representations,,A Cost Function for Internal Representations 733 A  Cost  Function for  Internal Representations Anders Krogh The Niels  Bohr Institute Blegdamsvej  17 2100  Copenhagen Denmark G. I.  Thorbergsson Nordita Blegdamsvej  17 2100  Copenhagen Denmark John A.  Hertz Nordita Blegdamsvej  17 2100  Copenhagen Denmark ABSTRACT We  introduce  a  cost  function  for  learning  in  feed-forward  neural networks  which  is  an  explicit  function  of the  internal representa(cid:173)tion  in  addition  to  the  weights.  The  learning  problem  can  then be formulated  as two simple perceptrons and  a  search for  internal representations.  Back-propagation  is  recovered  as  a  limit.  The frequency  of successful  solutions  is  better for  this  algorithm than for  back-propagation when  weights and hidden  units  are  updated on the same timescale i.e.  once  every learning step. 1 INTRODUCTION In  their  review  of back-propagation  in  layered  networks
1989,HMM Speech Recognition with Neural Net Discrimination,,194 Huang and Lippmann HMM Speech  Recognition with  Neural Net Discrimination* William Y.  Huang and Richard P.  Lippmann Lincoln  Laboratory
1989,The Eects of Circuit Integration on a Feature Map Vector Quantizer,,226  Mann The  Eects  of Circuit  Integration  on  a  Feature Map  Vector  Quantizer Jim  lVIann MIT Lincoln  Laboratory 244  Wood  St. Lexington
1989,Generalization and Parameter Estimation in Feedforward Nets: Some Experiments,,630 Morgan and Bourfard Generalization and Parameter Estimation in Feedforward Nets: Some Experiments ~. Morgant International Computer Science Institute Berkeley
1989,VLSI Implementation of a High-Capacity Neural Network Associative Memory,,VLSI Implementation of a High-Capacity Neural Network 793 VLSI Implementation of a  High-Capacity Neural Network Associative Memory Tzi-Dar  Chiueh 1  and Rodney  M.  Goodman Department of Electrical Engineering (116-81) California Institute of Technology Pasadena
1989,The Cascade-Correlation Learning Architecture,,524 Fablman and Lebiere The  Cascade-Correlation Learning Architecture Scott E. Fahlman and Christian Lebiere School of Computer Science Carnegie-Mellon University Pittsburgh
1989,Sigma-Pi Learning: On Radial Basis Functions and Cortical Associative Learning,,474  Mel and Koch Sigma-Pi Learning: On Radial Basis Functions and  Cortical Associative Learning Christof Koch Bartlett W.  Mel Computation and  Neural Systems Program Caltech
1989,Optimal Brain Damage,,598 Le Cun
1989,Learning Aspect Graph Representations from View Sequences,,258 Seibert and Waxman Learning  Aspect  Graph  Representations from  View  Sequences Michael  Seibert and Allen  M.  Waxnlan Lincoln  Laborat.ory
1989,The Eect of Catecholamines on Performance: From Unit to System Behavior,,100 Servan-Schreiber
1989,Meiosis Networks,,Meiosis Networks 533 Meiosis  Networks Stephen Jose  Hanson 1 Learning and Knowledge Acquisition  Group Siemens Research  Center Princeton
1989,Synergy of Clustering Multiple Back Propagation Networks,,650 Lincoln and Skrzypek Synergy Of Clustering Multiple Back Propagation Networks William P. Lincoln*  and Josef Skrzypekt UCLA Machine Perception Laboratory Computer Science Department Los Angeles
1989,Incremental Parsing by Modular Recurrent Connectionist Networks,,364 Jain and Waibel Incremental Parsing by Modular Recurrent Connectionist Networks Ajay N. Jain  Alex  H. Waibel School of Computer Science Carnegie Mellon  University Pittsburgh
1989,Reading a Neural Code,,36 Bialek
1989,A Method for the Associative Storage of Analog Vectors,,590 Atiya and Abu-Mostafa A Method for the Associative Storage of Analog Vectors Amir  Atiya (*)  and Yaser Abu-Mostafa (**) (*)  Department of Electrical Engineering (**)  Departments of Electrical  Engineering and Computer Science California Institute Technology Pasadena
1989,Using Local Models to Control Movement,,316 Atkeson Using  Local Models  to  Control Movement Christopher G.  Atkeson Department of Brain and Cognitive Sciences and  the Artificial Intelligence Laboratory Massachusetts Institute of Technology NE43-771
1989,Learning to Control an Unstable System with Forward Modeling,,324 Jordan and Jacobs Learning to  Control an  Unstable  System  with Forward  Modeling Michael I.  Jordan Brain and Cognitive Sciences MIT Cambridge
1989,Learning in Higher-Order Artificial Dendritic Trees,,490 Bell Learning  in  higher-order' artificial dendritic  trees' Tony Bell Artificial  Intelligence Laboratory Vrije Universiteit Brussel Pleinlaan  2
1989,Dynamic Behavior of Constained Back-Propagation Networks,,642 Chauvin Dynamic Behavior of Constrained Back-Propagation Networks Yves Chauvin! Thomson-CSF
1989,Designing Application-Specific Neural Networks Using the Genetic Algorithm,,Designing Application-Specific Neural Networks 447 Designing Application-Specific Neural Networks Using the  Genetic Algorithm Steven A.  Harp
1989,A Computational Basis for Phonology,,372 Touretzky and Wheeler A  Computational Basis for Phonology David S.  Touretzky School of Computer Science Carnegie Mellon  University Pittsburgh
1989,Neural Network Simulation of Somatosensory Representational Plasticity,,52 Grajski and Merzenich Neural  Network Simulation of Somatosensory Representational  Plasticity Kamil A. Grajski Ford Aerospace San Jose
1989,A Neural Network for Feature Extraction,,A Neural Network for Feature Extraction 719 A  Neural Network for  Feature  Extraction Nathan Intrator Div.  of Applied  Mathematics
1989,Generalized Hopfield Networks and Nonlinear Optimization,,Generalized Hopfield Networks and Nonlinear Optimization 355 Generalized Hopfield Networks and Nonlinear Optimization Gintaras v. Reklaitis Dept. of Chemical Eng. Purdue University W. Lafayette
1989,Connectionist Architectures for Multi-Speaker Phoneme Recognition,,Connectionist Architectures for Multi-Speaker Phoneme Recognition 203 Connectionist Architectures/or Multi-Speaker Phoneme Recognition John B. Hampshire n  and  Alex Waibel School of Computer Science Carnegie Mellon University Pittsburgh
1989,Bayesian Inference of Regular Grammar and Markov Source Models,,388 Smith and Miller Bayesian Inference of Regular Grammar and Markov Source Models Kurt R. Smith and Michael I. Miller Biomedical Computer Laboratory and Electronic Signals and Systems Research Laboratory Washington University
1989,Dataflow Architectures: Flexible Platforms for Neural Network Simulation,,818 Smotro Dataflow Architectures: Flexible Platforms for Neural Network Simulation Ira G. Smotro MITRE-Bedford Neural Network Group The MITRE Corporation Bedford
1989,The Perceptron Algorithm Is Fast for Non-Malicious Distributions,,676 Baum The Perceptron Algorithm Is Fast tor Non-Malicious Distributions Erice B. Baum NEC Research Institute 4 Independence Way Princeton
1989,Discovering High Order Features with Mean Field Modules,,Discovering High Order Features with Mean Field Modules 509 Discovering  high  order features  with  mean field modules Conrad C.  Galland and Georey  E.  Hinton Physics  Dept.  and Computer Science  Dept. University of Toronto Toronto
1989,Sequential Decision Problems and Neural Networks,,686 Barto
1989,Asymptotic Convergence of Backpropagation: Numerical Experiments,,606 Ahmad
1989,Training Connectionist Networks with Queries and Selective Sampling,,566 Atlas
1989,Unsupervised Learning in Neurodynamics Using the Phase Velocity Field Approach,,Unsupervised Learning in Neurodynamics 583 Unsupervised  Learning  in  Neurodynamics  Using the  Phase  Velocity  Field  Approach Michail  Zak Nikzad Toornarian Center for  Space  Microelectronics Technology Jet  Propulsion Laboratory California Institute of Technology Pasadena
1989,A Continuous Speech Recognition System Embedding MLP into HMM,,186 Bourlard and Morgan A  Continuous Speech Recognition System Embedding MLP  into HMM Herve Bourlard Philips Research Laboratory Av.  van  Becelaere 2. Box 8 B-1170 Brussels. Belgium Nelson  Morgan IntI.  Compo  Sc.  Institute 1947 Center Street. Suite 600 Berkeley. CA 94704. USA ABSTRACT We  are  developing  a  phoneme  based.  speaker-dependent  continuous speech  recognition  system  embedding  a  Multilayer Perceptron  (MLP) (Le .•  a  feedforward  Artificial  Neural  Network).  into  a Hidden  Markov Model (HMM) approach.  In [Bourlard &  Wellekens]. it was  shown that MLPs  were approximating Maximum  a Posteriori (MAP) probabilities and  could  thus  be  embedded  as  an  emission  probability  estimator  in HMMs.  By using contextual information from  a sliding window on the input frames.  we  have  been  able  to  improve  frame  or phoneme  clas(cid:173)sification  performance  over the  corresponding  performance  for Simple Maximum  Likelihood  (ML)  or even  MAP  probabilities  that  are  esti(cid:173)mated without the benefit of context.  However. recognition of words in continuous speech was  not so simply improved by the use of an  MLP. and  several  modifications  of the  original  scheme  were  necessary  for getting acceptable performance.  It is  shown here that word recognition performance for a  simple discrete density  HMM  system  appears  to  be somewhat better when MLP methods are used to estimate the emission probabilities. INTRODUCTION 1 We  have  performed  a  number  of experiments  with  a  1000-word  vocabulary  continu(cid:173)ous  speech  recognition  task.  Our  frame  classification  results  [Bourlard  et  al .•  1989] A Continuous Speech Recognition-System Embedding MLP into HMM 187 are consistent with  other research  showing  the capabilities  of MLPs  trained  with  back(cid:173)propagation-styled learning  schemes  for  the recognition of voiced-unvoiced  speech  seg(cid:173)ments  [Gevins  &  Morgan
1989,Analysis of Linsker's Simulations of Hebbian Rules,,694  MacKay and Miller Analysis  of Linsker's  Simulations of Hebbian rules David J.  C.  MacKay Computation and  Neural Systems Caltech 164-30 CNS Pasadena
1989,Analog Neural Networks of Limited Precision I: Computing with Multilinear Threshold Functions,,702 Obradovic and Pclrberry Analog  Neural  Networks  of Limited Precision I: Computing with  Multilinear Threshold Functions (Preliminary Version) Zoran Obradovic and Ian Parberry Department of Computer Science. Penn State University. University Park. Pa.  16802. ABSTRACT Experimental  evidence  has  shown  analog  neural  networks  to  be  ex(cid:173)~mely fault-tolerant
1989,A Systematic Study of the Input/Output Properties of a 2 Compartment Model Neuron With Active Membranes,,A Systematic Study or the Input/Output Properties 149 A Systematic Study of the Input/Output Properties of a 2 Compartment Model Neuron With Active Membranes Paul Rhodes University of California
1989,Subgrouping Reduces Complexity and Speeds Up Learning in Recurrent Networks,,638 Zipser Subgrouping Reduces Complexity and  Speeds Up Learning in  Recurrent Networks David Zipser Department of Cognitive Science University of California
1989,Neural Implementation of Motivated Behavior: Feeding in an Artificial Insect,,44 Beer and Chiel Neural  Implementation  of Motivated  Behavior: Feeding  in  an  Artificial Insect Randall D.  Beerl
1989,A Neural Network to Detect Homologies in Proteins,,A Neural Network to Detect Homologies in Proteins 423 A Neural Network to Detect Homologies in Proteins Y oshua Bengio School of Computer Science McGill University Montreal
1989,Higher Order Recurrent Networks and Grammatical Inference,,380 Giles
1989,Practical Characteristics of Neural Network and Conventional Pattern Classifiers on Artificial and Speech Problems,,168 Lee and Lippmann Practical  Characteristics  of Neural  Network and  Conventional Pattern  Classifiers  on Artificial and Speech  Problems* Yuchun Lee Digital Equipment Corp. 40  Old  Bolton Road
1989,Contour-Map Encoding of Shape for Early Vision,,282 Kanerva Contour-Map Encoding of Shape for Early Vision Research  Institute  for  Advanced  Computer  Science Pentti  Kanerva Mail  Stop  230-5
1989,Maximum Likelihood Competitive Learning,,574 Nowlan Maximum  Likelihood  Competitive  Learning Steven J. Nowlan1 Department of Computer Science University of Toronto Toronto
1989,Note on Development of Modularity in Simple Cortical Models,,Note on Development or Modularity in Simple Cortical Models 133 Note on Development of Modularity in Simple Cortical Models Alex Chernjavskyl Neuroscience Graduate Program Section of Molecular Neurobiology Howard Hughes Medical Institute Yale University John Moody2 Yale Computer Science PO Box 2158 Yale Station New Haven
1989,Model Based Image Compression and Adaptive Data Representation by Interacting Filter Banks,,298 Okamoto
1989,On the Distribution of the Number of Local Minima of a Random Function on a Graph,,On the Distribution of the Number of Local Minima 727 On  the  Distribution  of the  Number  of Local Minima  of a Random Function  on  a  Graph Pierre Baldi JPL
1989,Using a Translation-Invariant Neural Network to Diagnose Heart Arrhythmia,,240 Lee Using A Translation-Invariant Neural Network To Diagnose Heart Arrhythmia The lohns Hopkins University Applied Physics Laboratory Susan Ciarrocca Lee Laurel. Maryland 20707 ABSTRACT Distinctive electrocardiogram (EeG) patterns are created when the heart is beating normally and when a dangerous arrhythmia is present. Some devices which monitor the EeG and react to arrhythmias parameterize the ECG signal and make a diagnosis based on the parameters. The author discusses the use of a neural network to classify the EeG signals directly. without parameterization. The input to such a network must be translation-invariant. since the distinctive features of the EeG may appear anywhere in an arbritrarily-chosen EeG segment. The input must also be insensitive to the episode-to-episode and patient-to-patient variability in the rhythm pattern. 1 INTRODUCTION Figure 1 shows internally-recorded transcardiac ECG signals for one patient. The top trace is an example of normal sinus rhythm (NSR). The others are examples of two arrhythmias: ventricular tachycardia (V1) and ventricular fibrillation (VF). Visually. the patterns are quite distinctive. Two problems make recognition of these patterns with a neural net interesting. The first problem is illustrated in Figure 2. All traces in Figure 2 are one second samples of NSR. but the location of the QRS complex relative to the start of the sample is shifted. Ideally. one would like a neural network to recognize each of these presentations as NSR. without preprocessing the data to center it. The second problem can be discerned by examining the two VT traces in Figure 1. Although quite similar. the two patterns are not exactly the same. Substantial variation in signal shape and repetition rate for NSR and VT (VF is inherently random) can be expected. even among rhythms generated by a single patient. Patient-to-patient variations are even greater. The neural Using A Translation-Invariant Neural Network 241 network must ignore variations within rhythm types
1989,Non-Boltzmann Dynamics in Networks of Spiking Neurons,,Non-Boltzmann Dynamics in Networks of Spiking Neurons 109 Non-Boltzmann  Dynamics  in Networks  of Spiking  Neurons Michael  C.  Crair and William  Bialek Department of Physics
1989,The Moving Targets Training Algorithm,,558 Rohwer The  'Moving  Targets'  Training  Algorithm Richard Rohwer Centre for  Speech Technology Research Edinburgh University 80
1989,Performance Comparisons Between Backpropagation Networks and Classification Trees on Three Real-World Applications,,622 Atlas
1989,An Eicient Implementation of the Back-propagation Algorithm on the Connection Machine CM-2,,An Eicient Implementation of the Back-propagation Algorithm 801 A n  Eicient Implementation  of the  Back-propagation  Algorithm on the  Connection  Machine  CM-2 Xiru  Zhang!  Michael Mckenna  Jill P.  Mesirov  David L.  Waltz Thinking Machines  Corporation 245 First Street
1989,Algorithms for Better Representation and Faster Learning in Radial Basis Function Networks,,482 Saba and Keeler Algorithms/or Better Representation and Faster Learning in Radial Basis  Function Networks A vijit  Saba 1 James D. Keeler Microelectronics and Computer Technology corporation 3500 West Balcones Center Drive Austin
1989,The Cocktail Party Problem: Speech/Data Signal Separation Comparison between Backpropagation and SONN,,542 Kassebaum
1989,Real-Time Computer Vision and Robotics Using Analog VLSI Circuits,,750 Koch
1989,The CHIR Algorithm for Feed Forward Networks with Binary Weights,,516 Grossman The CHIR Algorithm for  Feed Forward Networks with Binary Weights Tal Grossman Department of Electronics Weizmann Institute of Science Rehovot 76100 Israel ABSTRACT A new learning algorithm
1989,A Large-Scale Neural Network Which Recognizes Handwritten Kanji Characters,,A Large-Scale Neural Network 415 A  LARGE-SCALE  NEURAL  NETWORK WHICH  RECOGNIZES  HANDWRITTEN KANJI  CHARACTERS Yoshihiro Mori Kazuki Joe A TR Auditory and Visual Perception Research Laboratories Sanpeidani Inuidani Seika-cho Soraku-gun Kyoto 619-02 Japan ABSTRACT We propose a  new  way  to construct a  large-scale neural  network  for 3.000 handwritten  Kanji  characters  recognition.  This  neural  network consists  of 3  parts:  a  collection  of small-scale  networks  which  are trained individually on a small number of Kanji characters
1989,Mechanisms for Neuromodulation of Biological Neural Networks,,18 Harris-Warrick MECHANISMS  FOR  NEUROMODULATION OF BIOLOGICAL NEURAL  NETWORKS Ronald  M.  Harris-Warrick Section of Neurobiology and Behavior Cornell University Ithaca
1989,Recognizing Hand-Printed Letters and Digits,,Recognizing Hand-Printed Letters and Digits 405 Recognizing Hand-Printed Letters and Digits Gale L.  Martin James A.  Pittman MCC
1989,TRAIC: Recognizing Objects Using Hierarchical Reference Frame Transformations,,266 Zemel
1989,Performance of Connectionist Learning Algorithms on 2-D SIMD Processor Arrays,,810 Nunez and Fortes Performance of Connectionist Learning Algorithms on 2-D SIMD Processor Arrays Fernando J. Nunez*  and  Jose A.B. Fortes School of Electrical Engineering Purdue University West Lafayette
1989,Neurally Inspired Plasticity in Oculomotor Processes,,290 Viola Neurally  Inspired  Plasticity in  Oculomotor Processes Paul A.  Viola Artificial Intelligence  Laboratory Massachusetts Institute of Technology Cambridge
1989,Combining Visual and Acoustic Speech Signals with a Neural Network Improves Intelligibility,,232 Sejnowski
1989,The Computation of Sound Source Elevation in the Barn Owl,,10 Spence and Pearson The Computation of Sound Source Elevation . 'In the Barn Owl Clay D. Spence John C. Pearson David Sarno Research Center CN5300 Princeton
1990,Modeling Time Varying Systems Using Hidden Control Neural Architecture,,Modeling Time Varying Systems Using Hidden  Control Neural Architecture Esther Levin AT&T Bell Laboratories Speech Research Department Murray Hill
1990,Using Genetic Algorithms to Improve Pattern Classification Performance,,Using  Genetic Algorithms to Improve Pattern Classification  Performance Eric I.  Chang and Richard P.  Lippmann Lincoln  Laboratory
1990,Generalization Dynamics in LMS Trained Linear Networks,,Generalization  Dynamics  in LMS  Trained Linear Networks Yves Chauvin· Psychology Department Stanford University Stanford
1990,Optimal Filtering in the Salamander Retina,,Optimal Filtering in the Salamander  Retina Fred Riekea
1990,Oscillation Onset in Neural Delayed Feedback,,Oscillation  Onset • In Neural Delayed Feedback Andre Longtin Complex Systems  Group and  Center for  Nonlinear  Studies Theoretical Division  B213
1990,Relaxation Networks for Large Supervised Learning Problems,,Relaxation Networks for Large Supervised Learning Problems Joshua Alspector  Robert B. Allen  Anthony Jayakumar Torsten Zeppenfeld and Ronny Meir Bellcore Morristown
1990,Neural Networks Structured for Control Application to Aircraft Landing,,Neural Networks Structured for Control Application to Aircraft Landing Charles Schley
1990,Closed-Form Inversion of Backpropagation Networks: Theory and Optimization Issues,,Closed-Form Inversion of Backpropagation Networks: Theory and Optimization Issues Michael L. Rossen HNC
1990,Dynamics of Generalization in Linear Perceptrons,,Dynamics of Generalization in Linear Perceptrons Anders  Krogh Niels  Bohr Institute Blegdamsvej  17 John A.  Hertz NORDITA Blegdamsvej  17 DK-2100  Copenhagen
1990,Translating Locative Prepositions,,Translating  Locative  Prepositions Paul  W.  Munro  and  Mary  Tabasko Department of Information Science University of Pittsburgh Pittsburgh
1990,Adaptive Spline Networks,,ADAPTIVE SPLINE  NETWORKS Jerome H.  Friedman Department of Statistics and Stanford Linear Accelerator  Center Stanford University Stanford
1990,An Analog VLSI Chip for Finding Edges from Zero-crossings,,An Analog VLSI  Chip for  Finding Edges from  Zero-crossings Wyeth Bair Christof Koch Computation and Neural Systems Program Caltech 216-76 Pasadena
1990,ART2/BP architecture for adaptive estimation of dynamic processes,,ART2/BP architecture for adaptive estimation of dynamic processes Einar S~rheim * Department of Computer Science UNIK
1990,Self-organization of Hebbian Synapses in Hippocampal Neurons,,Self-organization of Hebbian Synapses in Hippocampal Neurons Thomas H. Brown
1990,Connection Topology and Dynamics in Lateral Inhibition Networks,,Connection Topology and Dynamics in Lateral Inhibition Networks C. M. Marcus
1990,A Delay-Line Based Motion Detection Chip,,A Delay-Line Based Motion Detection Chip Tim Horiuchit John Lazzaro· Andrew Mooret Christof Kocht tComputation and Neural Systems Program ·Department of Computer Science California Institute of Technology MS 216-76 Pasadena
1990,Back Propagation is Sensitive to Initial Conditions,,Back Propagation is Sensitive to Initial Conditions John F. Kolen Jordan B. Pollack Laboratory for Artificial Intelligence Research The Ohio State University Columbus. OH 43210. USA kolen-j@cis.ohio-state.edu pollack@cis.ohio-state.edu Abstract functions  with learning  simple This paper explores the eect of initial weight selection on feed-forward the  back-propagation networks technique.  We  first  demonstrate.  through  the  use  of  Monte  Carlo techniques. that the magnitude of the initial condition vector (in weight space) is a very significant parameter in convergence time variability. In order  to  further  understand this  result.  additional  deterministic experiments  were  performed.  The  results  of  these  experiments demon~trate the extreme sensitivity of back propagation to initial weight configuration. INTRODUCTION 1 Back Propagation (Rwnelhart et al .•  1986) is  the network training method  of choice for many neural network projects. and for good reason. Like other weak methods
1990,Applications of Neural Networks in Video Signal Processing,,Applications of Neural Networks in Video Signal Processing John C. Pearson
1990,Grouping Contours by Iterated Pairing Network,,Grouping Contours by Iterated Pairing Network Amnon Shashua M.I.T. Artificial Intelligence Lab.
1990,Simulation of the Neocognitron on a CCD Parallel Processing Architecture,,Simulation of the Neocognitron  on a  CCD Parallel Processing  Architecture Michael L.  Chuang and  Alice M.  Chiang M.I.T Lincoln  Laboratory Lexington
1990,Order Reduction for Dynamical Systems Describing the Behavior of Complex Neurons,,Order Reduction for Dynamical Systems Describing the Behavior of Complex Neurons Thomas B. Kepler Biology Dept. L. F. Abbott Physics Dept. Eve Marder Biology Dept. Brandeis University Waltham
1990,Note on Learning Rate Schedules for Stochastic Optimization,,Note on Learning Rate  Schedules for  Stochastic Optimization Christian Darken and John Moody Yale University P.O.  Box  2158  Yale Station New  Haven
1990,Remarks on Interpolation and Recognition Using Neural Nets,,REMARKS  ON INTERPOLATION AND RECOGNITION  USING  NEURAL NETS Eduardo D.  Sontag· SYCON - Center for  Systems and  Control Rutgers  University New  Brunswick
1990,Rapidly Adapting Artificial Neural Networks for Autonomous Navigation,,Rapidly Adapting Artificial Neural Networks for Autonomous Navigation Dean A. Pomerleau School of Computer Science Carnegie Mellon University Pittsburgh
1990,A Recurrent Neural Network for Word Identification from Continuous Phoneme Strings,,A Recurrent Neural Network for Word Identification from Continuous Phoneme Strings Robert B. Allen Bellcore Morristown
1990,Adjoint-Functions and Temporal Learning Algorithms in Neural Networks,,Adjoint-Functions and Temporal Learning Algorithms in Neural Networks N. Toomarian and J. Barhen Jet Propulsion Laboratory California Institute of Technology Pasadena
1990,Language Induction by Phase Transition in Dynamical Recognizers,,Language Induction by Phase Transition in Dynamical Recognizers Jordan B. Pollack Laboratory for AI Research The Ohio State University Columbus
1990,Chaitin-Kolmogorov Complexity and Generalization in Neural Networks,,Chaitin-Kolmogorov Complexity and  Generalization in Neural Networks Barak A.  Pearlmutter School of Computer Science Carnegie Mellon  University Pittsburgh
1990,VLSI Implementations of Learning and Memory Systems: A Review,,VLSI Implementations of Learning and Memory Systems: A Review Mark A. Holler Intel Corporation 2250 Mission College Blvd. Santa Clara
1990,Neural Dynamics of Motion Segmentation and Grouping,,Neural Dynamics of Motion Segmentation and  Grouping Ennio Mingolla Center for  Adaptive Systems
1990,Exploratory Feature Extraction in Speech Signals,,Exploratory Feature  Extraction in  Speech  Signals Nathan Intrator Center  for  Neural Science Brown  U ni versity Providence
1990,Constructing Hidden Units using Examples and Queries,,Constructing Hidden Units using Examples and Queries Eric B. Baum Kevin J. Lang NEC Research Institute 4 Independence Way Princeton
1990,Analog Neural Networks as Decoders,,Analog Neural Networks as Decoders Ruth Erlanson· Dept. of Electrical Engineering California Institute of Technology Pasadena
1990,A Reinforcement Learning Variant for Control Scheduling,,A Reinforcement Learning Variant for Control Scheduling Honeywell  Sensor and  System  Development Center Aloke Guha 3660 Technology Drive Minneapolis
1990,Kohonen Networks and Clustering: Comparative Performance in Color Clustering,,Kohonen Networks and Clustering: Comparative Performance in Color Clustering Wesley Snyder Department of Radiology Bowman Gray School of Medicine Wake Forest University Winston-Salem
1990,Reconfigurable Neural Net Chip with 32K Connections,,Reconfigurable Neural Net Chip with 32K Connections H.P. Graf
1990,e-Entropy and the Complexity of Feedforward Neural Networks,,c-Entropy and the Complexity of Feedforward Neural Networks Robert C. Williamson Department of Systems Engineering Research School of Physical Sciences and Engineering Australian National University GPO Box 4
1990,Extensions of a Theory of Networks for Approximation and Learning: Outliers and Negative Examples,,Extensions of a Theory of Networks for Approximation and Learning: Outliers and Negative Examples Federico Girosi AI Lab. M.I.T. Tomaso Poggio Al Lab. M.LT. Cambridge
1990,Stochastic Neurodynamics,,Stochastic Neurodynamics J.D. Cowan Department of Mathematics
1990,Phonetic Classification and Recognition Using the Multi-Layer Perceptron,,Phonetic Classification and Recognition Using the Multi-Layer Perceptron Hong C. Leung
1990,Learning Trajectory and Force Control of an Artificial Muscle Arm by Parallel-hierarchical Neural Network Model,,Learning Trajectory and Force Control of an Artificial Muscle Arm by Parallel-hierarchical Neural Network Model Masazumi Katayama Mitsuo Kawato Cognitive Processes Department ATR Auditory and Visual Perception Research Laboratories Seika-cho. Soraku-gun. Kyoto 619-02. JAPAN Abstract We propose a new parallel-hierarchical neural network model to enable motor learning for simultaneous control of both trajectory and force. by integrating Hogan's control method and our previous neural network control model using a feedback-error-learning scheme. Furthermore. two hierarchical control laws which apply to the model
1990,Basis-Function Trees as a Generalization of Local Variable Selection Methods for Function Approximation,,Basis-Function Trees as a Generalization of Local Variable Selection Methods for Function Approximation Terence D. Sanger Dept. Electrical Engineering and Computer Science Massachusetts Institute of Technology
1990,A Short-Term Memory Architecture for the Learning of Morphophonemic Rules,,A  Short-Term Memory Architecture for  the Learning of Morphophonemic Rules Michael Gasser and  Chan-Do Lee Computer Science  Department Indiana University Bloomington
1990,Associative Memory in a Network of `Biological' Neurons,,Associative  Memory in a  Network of 'biological' Neurons \Vulfram Gerstner • Department of Physics University of California Ber keley
1990,Oriented Non-Radial Basis Functions for Image Coding and Analysis,,Oriented Non-Radial Basis Functions for Image Coding and Analysis A vijit Saha 1 Jim Christian D. S. Tang Microelectronics and Computer Technology Corporation 3500 West Balcones Center Drive Austin
1990,Evaluation of Adaptive Mixtures of Competing Experts,,Evaluation  of Adaptive  Mixtures of Competing  Experts Steven J.  Nowlan  and  Georey  E.  Hinton Computer Science  Dept. University of Toronto Toronto
1990,Spoken Letter Recognition,,Spoken Letter Recognition Mark Fanty & Ronald Cole Dept. of Computer Science and Engineering Oregon Graduate Institute Beaverton
1990,Design and Implementation of a High Speed CMAC Neural Network Using Programmable CMOS Logic Cell Arrays,,Design and Implementation of a High Speed CMAC Neural Network Using Programmable CMOS Logic Cell Arrays W. Thomas Miller
1990,Shaping the State Space Landscape in Recurrent Networks,,Shaping the State Space Landscape  in Recurrent Networks Patrice Y.  Simard  >I< Computer Science  Dept. University of Rochester Rochester
1990,Phase-coupling in Two-Dimensional Networks of Interacting Oscillators,,Phase-coupling in Two-Dimensional Networks  of Interacting Oscillators Ernst  Niebur
1990,An Analog VLSI Splining Network,,An Analog VLSI Splining Network Daniel B.  Schwartz and Vijay K.  Samalam GTE Laboratories
1990,Designing Linear Threshold Based Neural Network Pattern Classifiers,,Designing Linear Threshold Based Neural Network Pattern Classifiers Terrence L. Fine School of Electrical Engineering Cornell University Ithaca
1990,Qualitative structure from motion,,Qualitative structure from motion Daphna Weinshall Center for Biological Information Processing MIT
1990,Learning to See Rotation and Dilation with a Hebb Rule,,Learning to See Rotation and Dilation with a Hebb Rule Martin I. Sereno and Margaret E. Sereno Cognitive Science D-015 University of California
1990,A Comparative Study of the Practical Characteristics of Neural Network and Conventional Pattern Classifiers,,A Comparative Study of the Practical Characteristics of Neural Network and Conventional Pattern Classifiers Kenney Ng BBN Systems and Technologies Cambridge
1990,Real-time autonomous robot navigation using VLSI neural networks,,Real-time autonomous robot navigation using VLSI neural networks Lionel Tarassenko Michael Brownlow Gillian Marshall· Jon Tombs Department of Engineering Science Oxford University
1990,CAM Storage of Analog Patterns and Continuous Sequences with 3N2 Weights,,CAM Storage of Analog Patterns and Continuous Sequences with 3N2 Weights Bill Baird Dept Mathematics and Dept Molecular and Cell Biology
1990,Generalization Properties of Radial Basis Functions,,Generalization  Properties of Radial Basis Functions Sherif M.  Botros Christopher G.  Atkeson Brain and Cognitive Sciences  Department and the Artificial Intelligence Laboratory Massachusetts Institute of Technology Cambridge
1990,Learning Time-varying Concepts,,Learning Time-varying Concepts Anthony Kuh Dept. of Electrical Eng. U. of Hawaii at Manoa Honolulu
1990,A Theory for Neural Networks with Time Delays,,A Theory for Neural Networks with Time Delays Bert de Vries Department of Electrical Engineering University of Horida
1990,Natural Dolphin Echo Recognition Using an Integrator Gateway Network,,Natural Dolphin Echo Recog~ition Using an Integrator Gateway Network Herbert L. Roitblat Department of Psychology
1990,Compact EEPROM-based Weight Functions,,Compact  EEPROM-based Weight  Functions A.  Kramer
1990,Discovering Viewpoint-Invariant Relationships That Characterize Objects,,Discovering Viewpoint-Invariant  Relationships That  Characterize Objects Richard S.  Zemel  and  Georey  E.  Hinton Department of Computer Science University  of Toronto Toronto
1990,Reinforcement Learning in Markovian and Non-Markovian Environments,,Reinforcenlent  Learning in  Markovian and Non-Markovian  Environments Jiirgen Schmidhuber Institut fiir  Informatik Technische  Universitat Miinchen Arcistr.  21
1990,Second Order Properties of Error Surfaces: Learning Time and Generalization,,Second Order Properties of Error Surfaces : Learning Time and Generalization Yann Le Cun AT &T Bell Laboratories Crawfords Corner Rd. Holmdel
1990,Connectionist Music Composition Based on Melodic and Stylistic Constraints,,Connectionist Music Composition Based on Melodic and Stylistic Constraints Michael C. Mozer Department of Computer Science and Institute of Cognitive Science University of Colorado Boulder
1990,Transforming Neural-Net Output Levels to Probability Distributions,,Transforming Neural-Net  Output Levels to  Probability  Distributions John S.  Denker and Yann leCun AT&T Bell  Laboratories Holmdel
1990,Can neural networks do better than the Vapnik-Chervonenkis bounds?,,Can neural networks do better than the Vapnik-Chervonenkis bounds? David Cohn Dept. of Compo Sci. & Eng. University of Washington Seattle
1990,Discovering Discrete Distributed Representations with Iterative Competitive Learning,,Discovering Discrete Distributed Representations with Iterative Competitive Learning Michael C. Mozer Department of Computer Science and Institute of Cognitive Science University of Colorado Boulder
1990,A Neural Expert System with Automated Extraction of Fuzzy If-Then Rules and Its Application to Medical Diagnosis,,A Neural Expert System with Automated Extraction of Fuzzy If-Then Rules and Its Application to Medical Diagnosis Yoichi Hayashi* Department of Computer and Information Sciences Ibaraki University Hitachi-shi
1990,Leaning by Combining Memorization and Gradient Descent,,Learning by Combining Memorization and Gradient Descent John C. Platt Synaptics
1990,A Neural Network Approach for Three-Dimensional Object Recognition,,A  Neural Network Approach for Three-Dimensional Object Recognition Siemens AG
1990,Distributed Recursive Structure Processing,,Distributed Recursive Structure Processing Geraldine Legendre Department of Linguistics Yoshiro Miyata Optoelectronic Computing Systems  Center University  of Colorado Boulder
1990,Dynamics of Learning in Recurrent Feature-Discovery Networks,,Dynamics of Learning  in  Recurrent Feature-Discovery  Networks Todd  K.  Leen Department of Computer Science and  Engineering Oregon  Graduate Institute of Science &  Technology Beaverton
1990,Navigating through Temporal Dierence,,Navigating through Temporal Dierence Centre for Cognitive Science &. Department of Physics Peter Dayan University of Edinburgh 2 Buccleuch Place
1990,On the Circuit Complexity of Neural Networks,,On The Circuit Complexity of Neural Networks v. P. Roychowdhury Information Systems Laboratory Stanford University Stanford
1990,An Attractor Neural Network Model of Recall and Recognition,,An Attractor Neural  Network Model of Recall and  Recognition Eytan Ruppin Department of Computer Science School of Mathematical Sciences Sackler Faculty of Exact  Sciences Tel  Aviv University 69978
1990,Training Knowledge-Based Neural Networks to Recognize Genes in DNA Sequences,,Training Knowledge-Based Neural Networks to Recognize Genes in DNA Sequences Michiel O. Noordewier Computer Science Rutgers University New Brunswick
1990,ALCOVE: A Connectionist Model of Human Category Learning,,ALCOVE:  A  Connectionist  Model of Human Category Learning John K.  Kruschke Department of Psychology  and Cognitive Science Program Indiana University
1990,Multi-Layer Perceptrons with B-Spline Receptive Field Functions,,Multi-Layer Perceptrons with B-SpIine Receptive Field Functions Stephen H. Lane
1990,Planning with an Adaptive World Model,,Planning with an Adaptive World  Model Sebastian B.  Thrun German National Research Center for  Computer Science  (GMD) D-5205 St.  Augustin
1990,Simple Spin Models for the Development of Ocular Dominance Columns and Iso-Orientation Patches,,Simple Spin Models for the Development of Ocular Dominance Columns and Iso-Orientation Patches J.D. Cowan & A.E. Friedman Department of Mathematics. Committee on Neurobiology. and Brain Research Institute. The University of Chicago. 5734 S. Univ. Ave .• Chicago. Illinois 60637 Abstract Simple classical spin models well-known to physicists as the ANNNI and Heisenberg XY Models. in which long-range interactions occur in a pattern given by the Mexican Hat operator. can generate many of the structural properties characteristic of the ocular dominance columns and iso-orientation patches seen in cat and primate visual cortex. 1 INTRODUCTION In recent years numerous models for the formation of ocular dominance columns (Malsburg
1990,A Multiscale Adaptive Network Model of Motion Computation in Primates,,A  Multiscale  Adaptive  Network  Model  of Motion  Computation  in  Primates H.  Taichi  Wang Science Center
1990,Speech Recognition Using Connectionist Approaches,,Speech  Recognition using Connectionist Approaches Khalid Choukri SPRINT Coordinator CAP GEMINI  INNOVATION 118 rue  de  Tocqueville
1990,Feedback Synapse to Cone and Light Adaptation,,FEEDBACK SYNAPSE TO CONE AND LIGHT ADAPTATION Josef Skrzypek Machine Perception Laboratory UCLA - Los Angeles
1990,Direct memory access using two cues: Finding the intersection of sets in a connectionist model,,Direct memory access using two cues: Finding the intersection of sets in a connectionist model Janet Wiles
1990,Flight Control in the Dragonfly: A Neurobiological Simulation,,Flight Control in the Dragonfly: A Neurobiological Simulation William  E.  Faller  and  Marvin  W.  Luttges Aerospace Engineering Sciences
1990,A Framework for the Cooperation of Learning Algorithms,,A Framework for  the  Cooperation of  Learning  Algorithms Leon  Bottou Patrick  Gallinari Laboratoire de Recherche en Informatique Universite de Paris XI 91405 Orsay Cedex France Abstract We introduce a framework  for  training architectures composed of several modules. This framework
1990,Continuous Speech Recognition by Linked Predictive Neural Networks,,Continuous Speech Recognition by Linked  Predictive Neural Networks Joe Tebelskis
1990,A B-P ANN Commodity Trader,,A  B-P  ANN  Commodity  Trader Joseph  E.  Collard Martingale  Research  Corporation 100  Allentown  Pkwy.
1990,Statistical Mechanics of Temporal Association in Neural Networks,,Statistical Mechanics of Temporal Association in  Neural Networks with Delayed Interactions Andreas  V.M.  Herz Division of Chemistry Caltech  139-74 Pasadena
1990,Cholinergic Modulation May Enhance Cortical Associative Memory Function,,Cholinergic Modulation May Enhance Cortical Associative Memory Function Michael E. Hasselmo· Computation and Neural Systems Caltech 216-76 Pasadena
1990,Neural Network Application to Diagnostics and Control of Vehicle Control Systems,,Neural Network Application to Diagnostics and Control of Vehicle Control Systems Kenneth A. Marko Research Sta Ford Motor Company Dearborn
1990,Evolution and Learning in Neural Networks: The Number and Distribution of Learning Trials Aect the Rate of Evolution,,EVOLUTION AND LEARNING IN NEURAL NETWORKS: THE NUMBER AND DISTRIBUTION OF LEARNING TRIALS AECT THE RATE OF EVOLUTION Ron Keesing and David G. Stork* Ricoh California Research Center 2882 Sand Hill Road Suite 115 Menlo Park
1990,A Lagrangian Approach to Fixed Points,,A  Lagrangian  Approach to  Fixed  Points Eric Mjolsness Department of Computer Science Yale  University P.O.  Box 2158 Yale Station New  Haven
1990,Neural Network Implementation of Admission Control,,Neural Network Implementation of Admission Control Rodolfo A. Milito
1990,Computing with Arrays of Bell-Shaped and Sigmoid Functions,,Computing with Arrays of Bell-Shaped and Sigmoid Functions Jet  Propulsion Laboratory California Institute of Technology Pierre Baldi· Pasadena
1990,VLSI Implementation of TInMANN,,VLSI Implementation of TInMANN Matt Melton Tan Phan Doug Reeves Dave Van den Bout Electrical and Computer Engineering Dept. North Carolina State University Raleigh
1990,SEXNET: A Neural Network Identifies Sex From Human Faces,,SEXNET: A NEURAL NETWORK IDENTIFIES SEX FROM HUMAN FACES B.A. Golomb
1990,From Speech Recognition to Spoken Language Understanding: The Development of the MIT SUMMIT and VOYAGER Systems,,From Speech Recognition to Spoken Language Understanding: The Development of the MIT SUMMIT and VOYAGER Systems Victor Zue
1990,Generalization by Weight-Elimination with Application to Forecasting,,Generalization by Weight-Elimination with Application to Forecasting Andreas S. Weigend Physics Department Stanford University Stanford
1990,A Novel Approach to Prediction of the 3-Dimensional Structures of Protein Backbones by Neural Networks,,A Novel Approach to Prediction of the 3-Dimensional Structures of Protein Backbones by Neural Networks Henrik Fredholrn l 
1990,Back Propagation Implementation on the Adaptive Solutions CNAPS Neurocomputer Chip,,Back Propagation Implementation on the Adaptive Solutions CNAPS Neurocomputer Chip Hal McCartor Adaptive Solutions Inc. 1400 N.W. Compton Drive Suite 340 Beaverton
1990,Asymptotic slowing down of the nearest-neighbor classifier,,Asymptotic slowing down of the nearest-neighbor classifier Robert R. Snapp CS lEE Department University of Vermont Burlington
1990,Connectionist Approaches to the Use of Markov Models for Speech Recognition,,Connectionist Approaches  to  the  Use  of Markov  Models  for  Speech  Recognition Herve Bourlard t
1990,Signal Processing by Multiplexing and Demultiplexing in Neurons,,Signal Processing by Multiplexing and Demultiplexing in Neurons DavidC. Tam Division of Neuroscience Baylor College of Medicine Houston
1990,Lg Depth Estimation and Ripple Fire Characterization Using Artificial Neural Networks,,Lg DEPTH ESTIMATION AND RIPPLE FIRE CHARACTERIZA TION USING ARTIFICIAL NEURAL NETWORKS ENSCO
1990,RecNorm: Simultaneous Normalisation and Classification applied to Speech Recognition,,RecNorm: Simultaneous Normalisation and Classification applied to Speech Recognition John S. Bridle Royal Signals and Radar Est. Great Malvern UK WR143PS Stephen J. Cox British Telecom Research Labs. Ipswich UK IP57RE Abstract A particular form of neural network is described
1990,A four neuron circuit accounts for change sensitive inhibition in salamander retina,,A four neuron circuit accounts for change sensitive inhibition in salamander retina Jerey L. Teeters Lawrence Livennore Lab PO Box 808
1990,A Method for the Eicient Design of Boltzmann Machines for Classiication Problems,,A Method for the Eicient Design of Boltzmann Machines for Classification Problems Ajay Gupta and Wolfgang Maass· Department of Mathematics
1990,How Receptive Field Parameters Aect Neural Learning,,How Receptive Field Parameters Aect  Neural Learning Bartlett W.  Mel CNS  Program Caltech
1990,Proximity Eect Corrections in Electron Beam Lithography Using a Neural Network,,Proximity Eect Corrections in Electron Beam Lithography Using a Neural Network Robert C. Frye AT &T Bell Laboratories 600 Mountain A venue Murray Hill. NJ 08854 Kevin D. Cummings* AT&T Bell Laboratories 600 Mountain Avenue Murray Hill. NJ 08854 Edward A. Rietman AT&T Bell Laboratories 600 Mountain A venue Murray Hill. NJ 08854 Abstract We have used a neural network to compute corrections for images written by electron beams to eliminate the proximity eects caused by electron Iterative methods are eective. but require prohibitively scattering. computation time. We have instead trained a neural network to perform equivalent corrections. resulting in a significant speed-up. We have examined hardware implementations using both analog and digital electronic networks. Both had an acceptably small error of 0.5% compared to the iterative results. Additionally. we verified that the neural network correctly generalized the solution of the problem to include patterns not contained in its training set. We have experimentally verified this approach on a Cambridge Instruments EBMF 10.5 exposure system. 1 INTRODUCTION Scattering imposes limitations on the minImum feature sizes that can be reliably obtained with electron beam lithography. Linewidth corrections can be used to control the dimensions of isolated features (i.e. intraproximity. Sewell. 1978). but meet with little success when dealing with the same features in a practical context. where they are surrounded by other features (i.e. interproximity). Local corrections have been proposed using a self-consistent method of computation for the desired incident dose pattern (parikh. 1978). Such techniques require inversion of large matrices and prohibitive amounts of computation time. Lynch et al .• 1982. have proposed an analytical method for proximity corrections based on a solution of a set of approximate equations
1990,Exploiting Syllable Structure in a Connectionist Phonology Model,,Exploiting Syllable Structure in a Connectionist Phonology Model David S. Touretzky  Deirdre W. Wheeler School of Computer Science Carnegie Mellon University Pittsburgh
1990,Integrated Modeling and Control Based on Reinforcement Learning and Dynamic Programming,,Integrated Modeling and Control Based on Reinforcement Learning and Dynamic Programming Richard S. Sutton GTE Laboratories Incorporated Waltham
1990,A Connectionist Learning Control Architecture for Navigation,,A Connectionist Learning Control Architecture for Navigation Jonathan R. Bachrach Department of Computer and Information Science University of Massachusetts Amherst
1990,On Stochastic Complexity and Admissible Models for Neural Network Classifiers,,On Stochastic  Complexity and  Admissible Models  for  Neural Network  Classifiers Padhraic Smyth Communications  Systems  Research Jet Propulsion  Laboratory California Institute of Technology Pasadena
1990,Analog Computation at a Critical Point: A Novel Function for Neuronal Oscillations?,,Analog Computation at a Critical Point: A Novel Function for Neuronal Oscillations? Leonid Kruglyak and Willianl Bialek Depart.ment of Physics University of California at Berkeley Berkeley
1990,Integrated Segmentation and Recognition of Hand-Printed Numerals,,Integrated Segmentation and Recognition of Hand-Printed Numerals James D.  Keeler· MCC 3500 W.  Balcones  Ctr.  Dr. Austin
1990,Speech Recognition Using Demi-Syllable Neural Prediction Model,,Speech Recognition Using Demi-Syllable  Neural Prediction Model Ken-ichi Iso  and Takao Watanabe C  &  C  Information Technology  Research  Laboratories 4-1-1  Miyazaki
1990,A Recurrent Neural Network Model of Velocity Storage in the Vestibulo-Ocular Reflex,,A Recurrent Neural Network Model of Velocity Storage in the Vestibulo-Ocular Reflex Thomas J. Anastasio Department of Otolaryngology University of Southern California School of Medicine Los Angeles
1990,The Devil and the Network: What Sparsity Implies to Robustness and Memory,,The Devil and the Network: What Sparsity Implies to Robustness and Memory Sanjay Biswas and Santosh S. Venkatesh Department of Electrical Engineering University of Pennsylvania Philadelphia
1990,Development and Spatial Structure of Cortical Feature Maps: A Model Study,,Development  and  Spatial Structure of Cortical Feature  Maps:  A  Model  Study K.  0 berulayer Beckman-Institute University  of Illinois Urbana
1990,Connectionist Implementation of a Theory of Generalization,,Connectionist Implementation of a Theory of Generalization Roger N. Shepard Department of Psychology Stanford University Stanford
1990,Discrete Aine Wavelet Transforms For Anaylsis And Synthesis Of Feedfoward Neural Networks,,Discrete Aine Wavelet Transforms For Analysis And Synthesis Of Feedforward Neural Networks Y. c. Pati and P. S. Krishnaprasad Systems Research Center and Department of Electrical Engineering University of Maryland
1990,Convergence of a Neural Network Classifier,,Convergence  of a  Neural  Network  Classifier John  S.  Baras Systems  Research  Center University  of Maryland College  Park
1990,Optimal Sampling of Natural Images: A Design Principle for the Visual System,,Optimal Sampling of Natural Images: A Design Principle for the Visual System? William Bialek
1990,Time Trials on Second-Order and Variable-Learning-Rate Algorithms,,Time Trials on Second-Order and Variable-Learning-Rate Algorithms Richard Rohwer Centre for Speech Technology Research Edinburgh University 80
1990,A competitive modular connectionist architecture,,A competitive modular connectionist architecture Robert A. Jacobs and Michael I. Jordan Department of Brain & Cognitive Sciences Massachusetts Institute of Technology Cambridge
1990,A Model of Distributed Sensorimotor Control in the Cockroach Escape Turn,,A Model of Distributed Sensorimotor Control in the Cockroach Escape Turn R.D. Beer1
1990,A VLSI Neural Network for Color Constancy,,A VLSI Neural Network for Color Constancy Andrew Moore Computation and Neural Systems Program
1990,Stereopsis by a Neural Network Which Learns the Constraints,,Stereopsis by a Neural Network Which Learns the Constraints Alireza Khotanzad and Ying-Wung Lee Image Processing and Analysis Laboratory Electrical Engineering Department Southern Methodist University Dallas
1990,The Tempo 2 Algorithm: Adjusting Time-Delays By Supervised Learning,,The Tempo 2 Algorithm:  Adjusting Time-Delays By Supervised Learning Ulrich Bodenhausen and Alex Waibel School of Computer Science Carnegie Mellon University Pittsbwgh
1990,Learning Theory and Experiments with Competitive Networks,,Learning  Theory and  Experiments with Competitive Networks Gri L.  Bilbro North  Carolina State University Box 7914 Raleigh
1990,Further Studies of a Model for the Development and Regeneration of Eye-Brain Maps,,Further Studies of a Model for the Development and Regeneration of Eye-Brain Maps J.D. Cowan & A.E. Friedman Department of Mathematics
1990,The Recurrent Cascade-Correlation Architecture,,The Recurrent Cascade-Correlation Architecture Scott E. Fahlman School of Computer Science Carnegie Mellon University Pittsburgh
1990,Sequential Adaptation of Radial Basis Function Neural Networks and its Application to Time-series Prediction,,Sequential Adaptation of Radial Basis Function Neural Networks and its Application to Time-series Prediction v. Kadirkamanathan Engineering Department Cambridge University Cambridge CB2 IPZ
1991,English Alphabet Recognition with Telephone Speech,,English Alphabet Recognition with Telephone Speech Mark Fanty
1991,Recognizing Overlapping Hand-Printed Characters by Centered-Object Integrated Segmentation and Recognition,,Recognizing Overlapping Hand-Printed Characters by Centered-Object Integrated Segmentation and Recognition Gale L. Martin- & Mosfeq Rashid MCC Austin
1991,Adaptive Soft Weight Tying using Gaussian Mixtures,,Adaptive  Soft  Weight  Tying using  Gaussian  Mixtures Steven J.  Nowlan Computational  Neuroscience  Laboratory The Salk  Institute
1991,Multi-State Time Delay Networks for Continuous Speech Recognition,,Multi-State Time Delay Neural Networks for Continuous Speech Recognition Patrick Haner CNET Lannion A TSSIRCP 22301 LANNION
1991,Neural Network - Gaussian Mixture Hybrid for Speech Recognition or Density Estimation,,Neural Network - Gaussian Mixture Hybrid for Speech Recognition or Density Estimation Yoshua Bengio Dept. Brain and Cognitive Sciences Massachusetts Institute of Technology Cambridge
1991,Threshold Network Learning in the Presence of Equivalences,,Threshold  Network  Learning  in the Presence of Equivalences John Shawe-Taylor Department of Computer  Science Royal Holloway  and  Bedford  New  College University  of London Egham
1991,Node Splitting: A Constructive Algorithm for Feed-Forward Neural Networks,,Node Splitting: A Constructive Algorithm for Feed-Forward Neural Networks Mike Wynne-Jones Research Initiative in Pattern Recognition St. Andrews Road
1991,Structural Risk Minimization for Character Recognition,,Structural Risk Minimization for Character Recognition I. Guyon
1991,Computer Recognition of Wave Location in Graphical Data by a Neural Network,,Computer  Recognition  of  Wave  Location in  Graphical  Data  by  a  Neural  Network Donald  T.  Freeman School of Medicine University of Pittsburgh Pittsburgh. PA  15261 Abstract Five experiments were performed using several neural  network architectures to identify  the  location  of a  wave  in  the  time  ordered  graphical  results  from  a medical  test.  Baseline  results  from  the  first  experiment  found  correct identification of the  target  wave in  85%  of cases  (n=20).  Other  experiments investigated the eect of dierent architectures and preprocessing the raw data on the results.  The methods used seem most appropriate for time oriented graphical data  which  has  a clear starting point such  as  electrophoresis  Or  spectrometry rather than continuous teSts such as ECGs and EEGs. I INTRODUCTION Complex  wave  form  recognition  is  generally  considered  to  be  a  diicult  task  for machines.  Analytical approaches to this problem have been described and they work with reasonable accuracy  (Gabriel  et  al.  1980.  Valdes-Sosa  et al.  1987)  The  use  of these techniques
1991,Improved Hidden Markov Model Speech Recognition Using Radial Basis Function Networks,,Improved Hidden Markov Model Speech Recognition Using Radial Basis Function Networks Elliot Singer and Richard P. Lippmann Lincoln Laboratory
1991,Connectionist Optimisation of Tied Mixture Hidden Markov Models,,Connectionist  Optimisation of Tied Mixture Hidden Markov Models Steve  Renals Nelson Morgan ICSI Berkeley  CA  94704 USA Herve Bourlard L&H  Speech products leper  B-9800 Belgium Horacio Franco Michael Cohen SRI International Menlo  Park CA  94025 USA Abstract Issues  relating  to  the  estimation  of hidden  Markov  model  (HMM)  local probabilities are  discussed.  In  particular  we  note  the  isomorphism of ra(cid:173)dial  basis  functions  (RBF)  networks  to  tied  mixture  density  modellingj additionally  we  highlight  the  dierences  between  these  methods  arising from  the  dierent  training  criteria  employed.  We  present  a  method  in which  connectionist  training  can  be  modified  to  resolve  these  dierences and  discuss  some preliminary experiments.  Finally
1991,Principled Architecture Selection for Neural Networks: Application to Corporate Bond Rating Prediction,,Principled Architecture Selection for Neural Networks: Application to Corporate Bond Rating Prediction John Moody Department of Computer Science Yale University P. O. Box 2158 Yale Station New Haven
1991,Extracting and Learning an Unknown Grammar with Recurrent Neural Networks,,Extracting and Learning an Unknown Grammar with Recurrent Neural Networks C.L.Gnes·
1991,Network activity determines spatio-temporal integration in single cells,,Network activity determines spatio-temporal integration in single cells Ojvind Bernander
1991,Image Segmentation with Networks of Variable Scales,,Image Segmentation with Networks of Variable Scales Hans P.  Grar Craig R.  Nohl AT&T Bell Laboratories Crawfords Comer Road Holmdel
1991,Decoding of Neuronal Signals in Visual Pattern Recognition,,Decoding of Neuronal Signals  in Visual Pattern Recognition Emad N  Eskandar Barry J  Richmond Laboratory of Neuropsychology National Institute of Mental  Health Laboratory of Neuropsychology National Institute of Mental  Health Bethesda MD 20892  USA Bethesda MD 20892  USA John A  Hertz Lance M  Optican NORDITA B1egdamsvej  17 DK-2100  Copenhagen  0
1991,Learning in Feedforward Networks with Nonsmooth Functions,,Learning in Feedforward Networks with Nonsmooth Functions Nicholas J. Redding· Information Technology Division Defence Science and Tech. Org. P.O. Box 1600 Salisbury Adelaide SA 5108 Australia T.Downs Intelligent Machines Laboratory Dept of Electrical Engineering University of Queensland Brisbane Q 4072 Australia Abstract This paper is concerned with the problem of learning in networks where some or all of the functions involved are not smooth. Examples of such networks are those whose neural transfer functions are piecewise-linear and those whose error function is defined in terms of the 100 norm. Up to now
1991,Constructing Proofs in Symmetric Networks,,Constructing Proofs in Symmetric Networks Gadi Pinkas Computer Science Department Washington University Campus Box 1045 St. Louis
1991,A Weighted Probabilistic Neural Network,,A Weighted Probabilistic Neural Network David Montana Bolt Beranek and Newman Inc. 10 Moulton Street Cambridge
1991,Shooting Craps in Search of an Optimal Strategy for Training Connectionist Pattern Classifiers,,Shooting Craps in Search of an Optimal Strategy for Training Connectionist Pattern Classifiers J. B. Hampshire IT and B. V. K. Vijaya Kumar Department of Electrical & Computer Engineering Carnegie Mellon University Pittsbwgh. PA 15213-3890 hamps@speechl.cs.cmu.edu and kumar@gauss.ece.cmu.edu Abstract We compare two strategies for training connectionist (as well as non(cid:173)connectionist) models for statistical pattern recognition. The probabilistic strat(cid:173)egy is based on the notion that Bayesian discrimination (i.e .• optimal classifica(cid:173)tion) is achieved when the classifier learns the a posteriori class distributions of the random feature vector. The dierential strategy is based on the notion that the identity of the largest class a posteriori probability of the feature vector is all that is needed to achieve Bayesian discrimination. Each strategy is directly linked to a family of objective functions that can be used in the supervised training procedure. We prove that the probabilistic strategy -linked with error measure objective functions such as mean-squared-error and cross-entropy -typically used to train classifiers necessarily requires larger training sets and more complex classifier architectures than those needed to approximate the Bayesian discrim(cid:173)linked inant function. In contrast. we prove that the dierential strategy -with classificationfigure-of-merit objective functions (CF'MmoIlO) [3] -requires the minimum classifier functional complexity and the fewest training examples necessary to approximate the Bayesian discriminant function with specified pre(cid:173)cision (measured in probability of error). We present our proofs in the context of a game of chance in which an unfair C-sided die is tossed repeatedly. We show that this rigged game of dice is a paradigm at the root of all statistical pattern recognition tasks. and demonstrate how a simple extension of the concept leads us to a general information-theoretic model of sample complexity for statistical pattern recognition. 1125 1126 Hampshire and Kumar 1 Introduction Creating a connectionist pattern classifier that generalizes well to novel test data has recently focussed on the process of finding the network architecture with the minimum functional complexity necessary to model the training data accurately (see
1991,Multimodular Architecture for Remote Sensing Operations.,,Multimodular Architecture for Remote Sensing Operations. Sylvie Thiria(1
1991,Learning in the Vestibular System: Simulations of Vestibular Compensation Using Recurrent Back-Propagation,,Learning in the Vestibular System: Simulations of Vestibular Compensation Using Recurrent Back-Propagation Thomas J.  Anastasio University of Dlinois Beckman Institute 405 N.  Mathews Ave. Urbana
1991,Repeat Until Bored: A Pattern Selection Strategy,,Repeat Until  Bored:  A  Pattern  Selection  Strategy Paul  W.  Munro Depamnent of Information Science University of Pittsburgh Pittsburgh
1991,Refining PID Controllers using Neural Networks,,Refining PIn Controllers using Neural Networks Gary M. Scott Jude W. Shavlik Department of Chemical Engineering Department of Computer Sciences 1415 Johnson Drive University of Wisconsin Madison
1991,A Cortico-Cerebellar Model that Learns to Generate Distributed Motor Commands to Control a Kinematic Arm,,A Cortico-Cerebellar Model that Learns to Generate Distributed Motor Commands to Control a Kinematic Arm N.E. Berthier S.P. Singh A.G. Barto Department of Computer Science University of Massachusetts Amherst
1991,Linear Operator for Object Recognition,,Linear Operator for  Object  Recognition Ronen  Bssri Shimon Ullman· M.I.T.  Artificial Intelligence Laboratory and Department of Brain  and Cognitive Science 545 Technology Square Cambridge
1991,Learning Unambiguous Reduced Sequence Descriptions,,LEARNING  UNAMBIGUOUS  REDUCED SEQUENCE DESCRIPTIONS Jiirgen Schmidhuber Dept.  of Computer Science University  of Colorado Campus Box 430 Boulder
1991,Dynamically-Adaptive Winner-Take-All Networks,,Dynamically-Adaptive Winner-Take-All Networks Treat  E.  Laale Artif1cia1IntcUigeoce Laboratory Computer Science Department Univmity of California. Los Angeles. CA  90024 Abstract Winner-Take-All  (WTA)  networks.  in  which  inhibitory  interconnec(cid:173)tions are used to determine the most highly-activated of a pool of unilS. are an important part of many  neural network models.  Unfortunately
1991,Some Approximation Properties of Projection Pursuit Learning Networks,,Some Approximation Properties of Projection Pursuit Learning Networks Ying  Zhao  Christopher G.  Atkeson The Artificial Intelligence Laboratory Massachusetts Institute of Technology Cambridge
1991,Unsupervised learning of distributions on binary vectors using two layer networks,,Unsupervised learning of distributions on binary vectors using two layer networks Yoav Freund· Computer and Information Sciences University of California Santa Cruz Santa Cruz
1991,Best-First Model Merging for Dynamic Learning and Recognition,,Best-First Model Merging for Dynamic Learning and Recognition Stephen M. Omohundro International Computer Science Institute 1947 CenteJ' Street
1991,Neural Computing with Small Weights,,Neural  Computing with Small Weights Dept.  of Electrical &  Computer Engineering University  of California
1991,A Segment-Based Automatic Language Identification System,,A  Segment-based Automatic Language Identification System Yeshwant K.  Muthusamy &  Ronald A.  Cole Center for  Spoken Language Understanding Oregon  Graduate Institute of Science  and Technology Beaverton OR 97006-1999 Abstract We have developed  a four-language automatic language identification sys(cid:173)tem  for  high-quality  speech.  The  system  uses  a  neural  network-based segmentation algorithm to segment speech  into seven  broad phonetic cat(cid:173)egories.  Phonetic  and prosodic features  computed on  these  categories  are then  input to a  second  network that performs the language classification. The system was trained  and tested on separate sets  of speakers of Ameri(cid:173)can English
1991,A Topographic Product for the Optimization of Self-Organizing Feature Maps,,A Topographic Product for the Optimization of Self-Organizing Feature Maps -Hans-Ulrich Bauer
1991,Learning How to Teach or Selecting Minimal Surface Data,,Learning  How To  Teach or Selecting Minimal Surface  Data Davi Geiger Ricardo A.  Marques Pereira Siemens Corporate  Research
1991,Visual Grammars and Their Neural Nets,,Visual Grammars and  their Neural  Nets Eric  Mjolsness Department of Computer Science Yale University New  Haven
1991,Hierarchical Transformation of Space in the Visual System,,Hierarchical Transformation of Space in the Visual System Alexandre Pouget Stephen A.  Fisher Terrence J.  Sejnowski Computational Neurobiology  Laboratory The Salk Institute La Jolla
1991,Illumination and View Position in 3D Visual Recognition,,Illumination and  View Position in  3D Visual Recognition Amnon  Shashua M.LT.  Artificial  Intelligence Lab.
1991,Constant-Time Loading of Shallow 1-Dimensional Networks,,Constant-Time Loading of Shallow 1-Dimensional Networks Stephen Judd Siemens Corporate Research
1991,Combined Neural Network and Rule-Based Framework for Probabilistic Pattern Recognition and Discovery,,Combined Neural Network and Rule-Based Framework for Probabilistic Pattern Recognition and Discovery Hayit K. Greenspan and Rodney Goodman Department of Electrical Engineering California Institute of Technology
1991,Experimental Evaluation of Learning in a Neural Microsystem,,Experimental Evaluation of Learning in a Neural Microsystem Joshua Alspector Anthony Jayakumar Stephan Lunat Bellcore Morristown
1991,Recurrent Eye Tracking Network Using a Distributed Representation of Image Motion,,A  Neural  Network for  Motion  Detection of Drift-Balanced  Stimuli Hilary  Tunley* School of Cognitive and  Computer Sciences Sussex  University Brighton
1991,Against Edges: Function Approximation with Multiple Support Maps,,Against Edges: Function Approximation with Multiple Support Maps Trevor Darrell and Alex Pentland Vision and Modeling Group
1991,Induction of Multiscale Temporal Structure,,Induction of Multiscale Temporal  Structure Michael C.  Moser Department of Computer Science  &: Institute of Cognitive  Science University  of Colorado Boulder
1991,Locomotion in a Lower Vertebrate: Studies of the Cellular Basis of Rhythmogenesis and Oscillator Coupling,,Locomotion  in a  Lower Vertebrate: Studies of the Cellular Basis  of Rhythmogenesis and  Oscillator Coupling James  T.  Buchanan Department  of Biology Marquette  University Milwaukee
1991,Single Neuron Model: Response to Weak Modulation in the Presence of Noise,,SINGLE NEURON MODEL: RESPONSE TO WEAK MODULATION IN THE PRESENCE OF NOISE A. R. Bu/
1991,Fast Learning with Predictive Forward Models,,Fast Learning with Predictive Forward Models Carlos Brody· Dept. of Computer Science lIMAS
1991,Nonlinear Pattern Separation in Single Hippocampal Neurons with Active Dendritic Membrane,,Nonlinear Pattern Separation in Single Hippocampal Neurons with Active Dendritic Membrane Anthony M. Zador t t Depts. of Psychology and Cellular &  Molecular Physiology Yale University New Haven
1991,A Neural Network for Motion Detection of Drift-Balanced Stimuli,,A  Neural  Network for  Motion  Detection of Drift-Balanced  Stimuli Hilary  Tunley* School of Cognitive and  Computer Sciences Sussex  University Brighton
1991,Generalization Performance in PARSEC - A Structured Connectionist Parsing Architecture,,Generalization Performance in PARSEC-A Structured Connectionist Parsing Architecture Ajay N. Jain· School of Computer Science Carnegie Mellon University Pittsburgh
1991,Hierarchies of adaptive experts,,Hierarchies of adaptive experts Michael I. Jordan Robert A. Jacobs Department of Brain and Cognitive Sciences Massachusetts Institute of Technology Cambridge
1991,Optical Implementation of a Self-Organizing Feature Extractor,,Optical Implementation of a Self·Organizing Feature Extractor Dana Z. Anderson*
1991,A Neurocomputer Board Based on the ANNA Neural Network Chip,,A  Neurocomputer Board  Based on the ANNA Neural Network  Chip Eduard Sackinger
1991,Adaptive Synchronization of Neural and Physical Oscillators,,Adaptive Synchronization of Neural and Physical Oscillators Kenji Doya University of California
1991,Recurrent Networks and NARMA Modeling,,Recurrent Networks and N ARMA Modeling Jerome Connor Les E. Atlas Douglas R. Martin FT-lO Interactive Systems Design Laboratory Dept. of Electrical Engineering University of Washington Seattle
1991,ANN Based Classification for Heart Defibrillators,,ANN Based Classification for Heart Defibrillators M. Jabri
1991,Adaptive Development of Connectionist Decoders for Complex Error-Correcting Codes,,Adaptive Development of Connectionist Decoders for  Complex Error-Correcting Codes Sheri L.  Gish  Mario Blalull IBM  Rf'search  Division Almaden  Research  Center 650  Harry  Road San  Jose
1991,Self-organization in real neurons: Anti-Hebb in 'Channel Space'?,,Self-organisation in real neurons: Anti-Hebb in 'Channel Space'? Anthony J. Bell AI-lab
1991,Tangent Prop - A formalism for specifying selected invariances in an adaptive network,,Tangent Prop - A formalism for specifying selected invariances in an adaptive network Patrice Simard AT&T Bell Laboratories 101 Crawford Corner Rd Holmdel
1991,Human and Machine 'Quick Modeling',,Human and Machine 'Quick Modeling' Jakob Bernasconi Asea Brown Boveri Ltd Corporate Research CH-5405 Baden
1991,Practical Issues in Temporal Dierence Learning,,Practical Issues  in Temporal Dierence Learning Gerald  Tesauro IBM  Thomas J. Watson Research  Center P.  O.  Box  704 Yorktown Heights
1991,A Network of Localized Linear Discriminants,,A Network of Localized Linear Discriminants Martin S.  Glassman Siemens Corporate Research 755 College Road East Princeton
1991,Multi-Digit Recognition Using a Space Displacement Neural Network,,Multi-Digit  Recognition  Using  A  Space Displacement  Neural Network Ofer Matan*
1991,JANUS: Speech-to-Speech Translation Using Connectionist and Non-Connectionist Techniques,,JANUS: Speech-to-Speech Translation Using Connectionist and Non-Connectionist Techniques Alex Waibel·  Ajay N. Jain t Arthur McNair  Joe Tebelskis School of Computer Science Carnegie Mellon University Pittsburgh
1991,A Parallel Analog CCD/CMOS Signal Processor,,A Parallel Analog CCD/CMOS Signal Processor Charles  F.  Neugebauer Amnon  Yariv Department of Applied Physics California Institute of Technology Pasadena
1991,Iterative Construction of Sparse Polynomial Approximations,,Iterative Construction of Sparse Polynomial Approximations Terence D.  Sanger Massachusetts Institute of Technology Room E25-534 Cambridge
1991,A Computational Mechanism to Account for Averaged Modified Hand Trajectories,,A Computational Mechanism To Account For Averaged Modified Hand Trajectories Ealan A. Henis*and Tamar Flash Department of Applied Mathematics and Computer Science The Weizmann Institute of Science Rehovot 76100
1991,Learning Global Direct Inverse Kinematics,,Learning Global Direct Inverse Kinematics David DeMers· Computer Science &  Eng. UC San Diego La Jolla
1991,VISIT: A Neural Model of Covert Visual Attention,,VISIT:  A  Neural Model  of Covert Visual Attention Subutai Ahmad-Siemens Research  and Development
1991,Kernel Regression and Backpropagation Training With Noise,,Kernel Regression and Backpropagation Training with Noise Petri Koistinen and Lasse Holmstrom Rolf Nevanlinna Institute
1991,Recognition of Manipulated Objects by Motor Learning,,Recognition  of  Manipulated  Objects by  Motor  Learning Hiroaki  Gomi Mitsuo  Kawato A TR Auditory and Visual Perception Research Laboratories
